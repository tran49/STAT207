{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--# STAT 207: Data Science Exploration-->\n",
    "<h1 style=\"color:blue;\">Unit 14: Logistic Regression Variable Selection</h1>\n",
    "Previously we have been building models manually either by having specific variables in mind, or by making targeted comparisons between models with different variables. In this section we begin to explore more automated methods for modeling. The key concept is to embed a a model in a larger class of potential models and tune the models within this class. This tuning process is called **learning** the model, and starts us on the road to machine learning.\n",
    "\n",
    "A big issue in model selection is the temptation to fit bigger and bigger models in order to improve the fit to the training data. This tendancy is called **overfitting.** By overfitting the data at hand, we risk losing the ability to generalize the results to future data or larger populations, because the model is too fine tuned to the data at hand. \n",
    "\n",
    "Learning methods are designed to counteract the tendancy to overfit the data. A simple approach introduced in the previous section is to split the data randomly into training and testing subsets of the data. We do all the model building on the training data, and then assess the model using the test data. \n",
    "    \n",
    "<h1 style=\"color:blue;\">Topic 0: Review of Methods to Deal with Overfitting that We've Already Learned</h1> \n",
    "\n",
    "## For Linear Regression Models\n",
    "For linear regression models (such as the one below), what is a method that we talked about in the past for testing whether multiple explanatory variables were \"needed\" in the model?\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Ex**: Considering whether $x_2$ and $x_5$ are needed in the linear regression model below.\n",
    "<br/>\n",
    "$\n",
    "\\hat{y}=\\hat{\\beta_0}+\\hat{\\beta_1}x_1+\\hat{\\beta_2}x_2+\\hat{\\beta_3}x_3+\\hat{\\beta_4}x_4+\\hat{\\beta_5}x_5$\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## For Logistic Regression Models \n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 1 (Definitions/Theory): How to Describe the Tradeoff Between Overfitting a Model and Underfitting a Model</h1> \n",
    "\n",
    "## Bias\n",
    "\n",
    "We define the **bias of a model** $\\hat{Y}=\\hat{\\beta_0}+\\hat{\\beta_1}x_1+\\hat{\\beta_2}x_2+...+\\hat{\\beta_p}x_p$ as:\n",
    "\n",
    "$Bias(\\hat{Y})=E[\\hat{Y}]-\\mu$\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "#### Idea: Bias is likely to be higher in models that are: ________________________________\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## Variance\n",
    "\n",
    "We define the **variance of a model** $\\hat{Y}=\\hat{\\beta_0}+\\hat{\\beta_1}x_1+\\hat{\\beta_2}x_2+...+\\hat{\\beta_p}x_p$ as:\n",
    "\n",
    "$Var(\\hat{Y})=E[(\\hat{Y} - E(\\hat{Y}))^2]$\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "#### Idea: Variance is likely to be higher in models that are: ________________________________\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "The idea is that simpler models might be biased due to some missing variables or transformations, so $E[\\hat{Y}] \\ne \\mu$, but if the bias is not too large compared to the variance reduction they provide, the mean square error can be improved over larger, less biased models with larger variance. If we go too far in this direction, however, the bias will overtake the variance. So we expect there will be some optimal model between the two extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Square Error (MSE)\n",
    "Finally, we define the **mean square error** of a model as \n",
    "\n",
    "$E[(\\hat{Y} - \\mu)^2]$\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "A key modeling aim is to find an effective compromise between bias reduction and variance reduction, for example, by searching for models with small **mean square error** for prediction, such a compromise might be found.\n",
    "\n",
    "Fundamental bias-variance decomposition for model prediction $\\hat{Y}$:\n",
    "\n",
    "\n",
    "## Bias-Variance Tradeoff Relationship\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "MSE(\\hat{Y}) = E[(\\hat{Y} - \\mu)^2] &= \\\\ \\\\\n",
    "                                    &= \\\\ \\\\\n",
    "                                    &= \\\\ \\\\\n",
    "                                    &=E[(\\hat{Y} - E(\\hat{Y}))^2] + [E(\\hat{Y}) - \\mu]^2 \\\\ \\\\\n",
    "                                    & = Var(\\hat{Y}) + Bias^2(\\hat{Y}).\\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "### Relationship\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section explores several methodologies useful in model selection, aimed at addressing the overfit/underfit challenge:\n",
    "\n",
    "\n",
    "+ **Log-Likelihood-Ratio Tests** for comparing nested logistic regression models; analogous to F-tests in ANOVA\n",
    "\n",
    "\n",
    "+ **Information criteria such as AIC and BIC** that trade off model fit with model complexity\n",
    "\n",
    "\n",
    "+ **Train/Test data splitting** to evaluate model based classifiers for sensitivy, specificity and accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python libraries and functions:\n",
    "\n",
    "    statsmodels.api\n",
    "    statsmodels.formula.api\n",
    "        logit\n",
    "    scipy.stats\n",
    "        bernoulli\n",
    "        chi2\n",
    "        norm\n",
    "    sklearn.model_selection\n",
    "        train_test_split\n",
    "    sklearn.metrics\n",
    "        accuracy_score\n",
    "        confusion_matrix\n",
    "        roc_curve\n",
    "        roc_auc_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 2: Maximum Likelihood Estimation for Determining Logistic Regression Model Parameters </h1> \n",
    "\n",
    "\n",
    "\n",
    "Recall that in linear regression modeling it can be useful to test between two models using an analysis of variance F test, which compares the residual sums of squares for two, nested models. It allows us to test multiple parameters within one hypothesis test. \n",
    "\n",
    "In logistic regression modeling, the F test is no longer applicable. However, the same general testing idea is possible by comparing log-likelihoods between two nested models. The change in log-likelihood is used as a large sample chi-square test of the null hypothesis that the simpler model is adequate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are the optimal values of $\\hat{\\beta_0}$, $\\hat{\\beta_1}$, ..., $\\hat{\\beta_p}$ determined in a logistic regression model?\n",
    "\n",
    "### 1. Assumption Behind Logistic Regression\n",
    "* Each $y_1$, $y_2$,...,$y_n$ are independent.\n",
    "* $y_i\\sim Bern(p_i)$, where\n",
    "* $\\log\\left({p_i \\over 1-p_i}\\right) = \\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}, \\quad \\mbox{for} \\quad i=1, 2, \\ldots, n.$\n",
    "    - Put another way: $p_i = \\frac{e^{\\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}}}{1+e^{\\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}}}$\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### 2. Representing the Response Variable Probabilities\n",
    "\n",
    "#### How can we represent the probability mass function of $y_i$, given the explanatory variable values and a given logistic regression model $\\log\\left({p_i \\over 1-p_i}\\right) = \\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}, \\quad \\mbox{for} \\quad i=1, 2, \\ldots, n.$ (ie. $p_i = \\frac{e^{\\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}}}{1+e^{\\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}}}$)?\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Answer:** $P(y_i|\\beta_0,\\beta_1,...,\\beta_n,X_i)=p_i^{y_i} (1-p_i)^{1-y_i}$\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### How can we represent the JOINT probability mass function of $y_1$,$y_2$,...,$y_n$ given the explanatory variable values and a given logistic regression model $\\log\\left({p_i \\over 1-p_i}\\right) = \\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}, \\quad \\mbox{for} \\quad i=1, 2, \\ldots, n.$  (ie. $p_i = \\frac{e^{\\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}}}{1+e^{\\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}}}$)?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "**Answer:** In binary response models such as logistic regression the **likelihood function (LF)** is the joint probability mass function of the responses viewed as a function of the parameters. For a logit model with independent Bernoulli responses, the likelihood function has the form:\n",
    "\n",
    "$\n",
    "{LF}(\\beta_0, \\beta_1, \\ldots, \\beta_p) = \\prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i}\n",
    "$\n",
    "\n",
    "where\n",
    "\n",
    "$\n",
    "\\log\\left({p_i \\over 1-p_i}\\right) = \\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}, \\quad \\mbox{for} \\quad i=1, 2, \\ldots, n.\n",
    "$\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### 3. Goal: Determine the best values of $\\hat{\\beta_0}$, $\\hat{\\beta_1}$, ..., $\\hat{\\beta_p}$ that maximize the likelihood function.\n",
    "\n",
    "**Maximize with respect to $\\beta_0, \\beta_1, \\ldots, \\beta_p$**\n",
    "\n",
    "$\n",
    "{LF}(\\beta_0, \\beta_1, \\ldots, \\beta_p) = \\prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i}\n",
    "$\n",
    "\n",
    "where\n",
    "\n",
    "$\n",
    "\\log\\left({p_i \\over 1-p_i}\\right) = \\beta_0 + \\beta_1 X_{i1} + \\cdots \\beta_p X_{ip}, \\quad \\mbox{for} \\quad i=1, 2, \\ldots, n.\n",
    "$\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### Can we transform the likelihood function into another function that gives us the same optimal values of $\\hat{\\beta_0}$, $\\hat{\\beta_1}$, ..., $\\hat{\\beta_p}$, but is easier to take the derivative of?\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Answer:**\n",
    "The logarithmic tranformation converts the product to a sum of log values, the log-likelihood function (LLF):\n",
    "$\n",
    "{LLF}(\\beta_0, \\beta_1, \\ldots, \\beta_p) = \\sum_{i=1}^n \\{ y_i \\log(p_i) + (1-y_i) \\log(1-p_i)\\}.\n",
    "$\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "### 4.  Where can we find this optimal value to the log-likelihood function?\n",
    "The result reported in the model summary (listed as 'Log-Likelihood') is the optimized value computed by **maximum likelihood estimation**:\n",
    "\n",
    "$\n",
    "{llf} = LLF(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p) \n",
    "= \\sum_{i=1}^n \\{ y_i \\log(\\hat{p}_i) + (1-y_i) \\log(1-\\hat{p}_i)\\}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 3: Log-likelihood Ratio Test: For Comparing two Logistic Regression Models </h1> \n",
    "\n",
    "## Step 1: Two Nested Logistic Regression Models\n",
    "\n",
    "### Model 1:\n",
    "\n",
    "$\\mbox{logit}(p) = \\log\\left({p \\over 1-p}\\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p.$\n",
    "\n",
    "\n",
    "### Model 0:  ...\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "$\\mbox{logit}(p) = \\log\\left({p \\over 1-p}\\right) = $\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "In order to test between two logit models, Model 0 and Model 1, where Model 0 is a special case of Model 1 obtained by setting some regression coefficients equal to zero.\n",
    "\n",
    "## Step 2: Set up two hypotheses\n",
    "\n",
    " Consider one is a special case of the other we can compare their log-likelihood ratios. Consider testing:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "H_0: &\\quad \\mbox{Model 0 is correct},\\\\\n",
    "\\\\\n",
    "H_A: &\\quad \\mbox{Model 0 is incorrect because at least one missing coefficient from Model 1 is not zero}.\\\\\n",
    "\\end{align}\n",
    "$\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "## Step 3: Test Statistic\n",
    "\n",
    "A general result from large sample theory is if $H_0$ is true, then twice the difference in negative log-likelihoods\n",
    "\n",
    "$\n",
    "llr = -2\\, (llf_0 - llf_1) \n",
    "$\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## Step 4: What distribution is this test statistic an observation from (and what degrees of freedom should it have)?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "This test statistic has an approximate Chi-square distribution with degrees of freedom equal to the difference in the numbers of parameters for the two models. Like the central limit theorem, this approximation works better for larger sample size $n$.\n",
    "\n",
    "\n",
    "### Some Properties of Chi-Squared Distribution:\n",
    "1. Positive distribution.\n",
    "2. Parameter that Determines Shape of Distribution: degrees of freedom value\n",
    "\n",
    "## Step 5: Use this test statistic and Chi-Squared distribution to find the p-value that corresponds to these hypotheses. Use the p-value to make a conclusion about the hypotheses.\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "Applying this test in our example lets us evaluate multiple coefficients at the same time to determine whether we can reduce to the simpler model.\n",
    "\n",
    "\n",
    "### Some Properties of Calculating the p-value with Chi-Squared Distribution for this Test\n",
    "1. Just use a right-tail.\n",
    "\n",
    "\n",
    "Here's how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 4: Pew Research Survey Example (Model Selection with Log Likelihood Ratio Test)</h1> \n",
    "\n",
    "## Using Log-likelihood Ratio Test For Comparing two Logistic Regression Models\n",
    "\n",
    "In an earlier section we considered two models for predicting a favorable opinion of border wall construction in the Pew Research Survey of February 2017. Let's load the data and the two models and first see how we can test between the two models. The idea is analogous to the ANOVA method for comparing two linear regression models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile as zp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zp.ZipFile('../data/Feb17-public.zip')\n",
    "missing_values = [\"NaN\", \"nan\", \"Don't know/Refused (VOL.)\"]\n",
    "df = pd.read_csv(zf.open('Feb17public.csv'), \n",
    "                 na_values=missing_values)[['age', 'sex', 'q52', 'party']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce q52 responses to two categories \n",
    "# and create binary reponse variable\n",
    "df['q52'][df['q52']!='Favor'] = 'Not_favor'\n",
    "df['y'] = df['q52'].map({'Not_favor':0,'Favor':1})\n",
    "# use cleaned data without records that have missing values\n",
    "dfclean = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>q52</th>\n",
       "      <th>party</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not_favor</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not_favor</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not_favor</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Favor</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not_favor</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     sex        q52        party  y\n",
       "0  80.0  Female  Not_favor  Independent  0\n",
       "1  70.0  Female  Not_favor     Democrat  0\n",
       "2  69.0  Female  Not_favor  Independent  0\n",
       "3  50.0    Male      Favor   Republican  1\n",
       "4  70.0  Female  Not_favor     Democrat  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfclean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Democrat                527\n",
       "Independent             525\n",
       "Republican              367\n",
       "No preference (VOL.)     41\n",
       "Other party (VOL.)        5\n",
       "Name: party, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfclean['party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      760\n",
       "Female    705\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfclean['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1465.000000</td>\n",
       "      <td>1465.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.522867</td>\n",
       "      <td>0.341297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.843611</td>\n",
       "      <td>0.474307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age            y\n",
       "count  1465.000000  1465.000000\n",
       "mean     50.522867     0.341297\n",
       "std      17.843611     0.474307\n",
       "min      18.000000     0.000000\n",
       "25%      35.000000     0.000000\n",
       "50%      52.000000     0.000000\n",
       "75%      65.000000     1.000000\n",
       "max      96.000000     1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfclean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Descriptive Analytics Question:</u> Is the proportion of people that support the border wall different for at least one pair of political parties *in the sample*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>party</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Democrat</th>\n",
       "      <td>50.499051</td>\n",
       "      <td>0.077799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>46.807619</td>\n",
       "      <td>0.306667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No preference (VOL.)</th>\n",
       "      <td>43.146341</td>\n",
       "      <td>0.317073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other party (VOL.)</th>\n",
       "      <td>44.600000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Republican</th>\n",
       "      <td>56.776567</td>\n",
       "      <td>0.768392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            age         y\n",
       "party                                    \n",
       "Democrat              50.499051  0.077799\n",
       "Independent           46.807619  0.306667\n",
       "No preference (VOL.)  43.146341  0.317073\n",
       "Other party (VOL.)    44.600000  0.600000\n",
       "Republican            56.776567  0.768392"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfclean.groupby('party').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the proportion of 'favor' responses varies quite a bit between party affiliations, by looking at the mean values for 'y'. In each subgroup, the sample mean of y equals the proportion who favored building the wall.\n",
    "\n",
    "\n",
    "## <u> Inference Question:</u> Is the proportion of people that support the border wall different for at least one pair of political parties *in the population* of all adults that live in the U.S.?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a Full model and reduced model for log-likelihood-ratio test\n",
    "\n",
    "Recall that 'party' is a categorical variable with 5 categories. If we wish to test the null hypothesis of no party effects, we need a 4 degree of freedom test. For this we can use the log-likelihood-ratio test.\n",
    "\n",
    "### Step 1: Set up a full model and a null model.\n",
    "\n",
    "* **Null Model (Model 0)**:\n",
    "    * Response = Support for Border Wall\n",
    "    * Explanatory Variables:\n",
    "        - age\n",
    "        - sex\n",
    "* **Full Model (Model 1)**:\n",
    "    * Response = Support for Border Wall\n",
    "    * Explanatory Variables:\n",
    "        - age\n",
    "        - sex\n",
    "        - party\n",
    "\n",
    "\n",
    "First we fit the null and full model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.619057\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.466129\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "model0 = smf.logit('y ~ age + sex', data=dfclean).fit()\n",
    "model1 = smf.logit('y ~ party + age + sex', data=dfclean).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set up the null and alternative hypotheses.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "H_0: &\\quad \\mbox{Model 0 is correct},\\\\\n",
    "\\\\\n",
    "H_A: &\\quad \\mbox{Model 0 is incorrect because the missing 'party' coefficient in model 0 is not zero}.\\\\\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the test statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to display the summaries to perform the test, but it is informative to review the model summaries to understand the variables. The maximized log-likelihood is shown in the model summary as 'Log-Likelihood'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3a: Extract the log-likelihoods for the two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>  1465</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1462</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 19 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.03557</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:05:08</td>     <th>  Log-Likelihood:    </th> <td> -906.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -940.37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.960e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>   -2.0818</td> <td>    0.196</td> <td>  -10.637</td> <td> 0.000</td> <td>   -2.465</td> <td>   -1.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex[T.Male]</th> <td>    0.5415</td> <td>    0.114</td> <td>    4.750</td> <td> 0.000</td> <td>    0.318</td> <td>    0.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>         <td>    0.0220</td> <td>    0.003</td> <td>    6.770</td> <td> 0.000</td> <td>    0.016</td> <td>    0.028</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1465\n",
       "Model:                          Logit   Df Residuals:                     1462\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Thu, 19 Nov 2020   Pseudo R-squ.:                 0.03557\n",
       "Time:                        11:05:08   Log-Likelihood:                -906.92\n",
       "converged:                       True   LL-Null:                       -940.37\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.960e-15\n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept      -2.0818      0.196    -10.637      0.000      -2.465      -1.698\n",
       "sex[T.Male]     0.5415      0.114      4.750      0.000       0.318       0.765\n",
       "age             0.0220      0.003      6.770      0.000       0.016       0.028\n",
       "===============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>  1465</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  1458</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 19 Nov 2020</td> <th>  Pseudo R-squ.:     </th>   <td>0.2738</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:05:08</td>     <th>  Log-Likelihood:    </th>  <td> -682.88</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -940.37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.971e-108</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                     <td>   -3.5261</td> <td>    0.281</td> <td>  -12.536</td> <td> 0.000</td> <td>   -4.077</td> <td>   -2.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>party[T.Independent]</th>          <td>    1.6843</td> <td>    0.191</td> <td>    8.796</td> <td> 0.000</td> <td>    1.309</td> <td>    2.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>party[T.No preference (VOL.)]</th> <td>    1.8226</td> <td>    0.379</td> <td>    4.807</td> <td> 0.000</td> <td>    1.079</td> <td>    2.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>party[T.Other party (VOL.)]</th>   <td>    2.8930</td> <td>    0.938</td> <td>    3.083</td> <td> 0.002</td> <td>    1.054</td> <td>    4.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>party[T.Republican]</th>           <td>    3.5862</td> <td>    0.206</td> <td>   17.435</td> <td> 0.000</td> <td>    3.183</td> <td>    3.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex[T.Male]</th>                   <td>    0.3721</td> <td>    0.137</td> <td>    2.712</td> <td> 0.007</td> <td>    0.103</td> <td>    0.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                           <td>    0.0168</td> <td>    0.004</td> <td>    4.305</td> <td> 0.000</td> <td>    0.009</td> <td>    0.024</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1465\n",
       "Model:                          Logit   Df Residuals:                     1458\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Thu, 19 Nov 2020   Pseudo R-squ.:                  0.2738\n",
       "Time:                        11:05:08   Log-Likelihood:                -682.88\n",
       "converged:                       True   LL-Null:                       -940.37\n",
       "Covariance Type:            nonrobust   LLR p-value:                4.971e-108\n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "Intercept                        -3.5261      0.281    -12.536      0.000      -4.077      -2.975\n",
       "party[T.Independent]              1.6843      0.191      8.796      0.000       1.309       2.060\n",
       "party[T.No preference (VOL.)]     1.8226      0.379      4.807      0.000       1.079       2.566\n",
       "party[T.Other party (VOL.)]       2.8930      0.938      3.083      0.002       1.054       4.732\n",
       "party[T.Republican]               3.5862      0.206     17.435      0.000       3.183       3.989\n",
       "sex[T.Male]                       0.3721      0.137      2.712      0.007       0.103       0.641\n",
       "age                               0.0168      0.004      4.305      0.000       0.009       0.024\n",
       "=================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-906.9182356126391, -682.8795444475213)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.llf, model1.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 6.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.df_model, model1.df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b: Use these log-likelihoods to calculate the likelihood ratio test statistic.\n",
    "\n",
    "Just be careful to get the multiplier (-2) right so the chi-sqaure approximation works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-2*llf</th>\n",
       "      <th>df_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model0</th>\n",
       "      <td>1813.836471</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>1365.759089</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>448.077382</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             -2*llf  df_model\n",
       "model0  1813.836471       2.0\n",
       "model1  1365.759089       6.0\n",
       "diff     448.077382       4.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract log-likelihood function values \n",
    "# and model degrees of freedom from each model\n",
    "llf0, df0 = model0.llf, model0.df_model\n",
    "llf1, df1 = model1.llf, model1.df_model\n",
    "# take differences\n",
    "llr, dfdiff = -2*(llf0 - llf1), df1 - df0\n",
    "# display results\n",
    "pd.DataFrame({'-2*llf': [-2*llf0, -2*llf1, llr], \n",
    "              'df_model': [df0, df1, dfdiff]}, \n",
    "             index=['model0','model1', 'diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate the degrees of freedom for the chi-squared distribution that this test statistic is an observation from.\n",
    "\n",
    "Why was df = 4 in this analysis?\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "### Step 5: Calculate the p-value and make a conclusion.\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import chisquare function and compute p-value\n",
    "from scipy.stats import chi2\n",
    "1 - chi2.cdf(llr, df=dfdiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the test with calculated p-value using chi-square distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2*llr: 448.08  df: 4.0  p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# summarize test results\n",
    "print('-2*llr:', round(llr, 2), \\\n",
    "      ' df:', dfdiff, ' p-value:', \\\n",
    "      1 - chi2.cdf(llr, df=dfdiff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** We definitely reject the null hypothesis and favor Model 1 over Model 0. Party affiliation is a significant factor associated with the response to question 52 in the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 5: Model Selection with AIC and BIC</h1> \n",
    "\n",
    "\n",
    "## Two metrics that measure the balance between having a good model fit and a small number of variables.\n",
    "\n",
    "\n",
    "AIC and BIC are criteria for evaluating a model that combine the likelihood asessment of fit with a penalty for complex models. Historically they were derived from different perspectives. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Akaike Information Criterion (AIC)\n",
    "\n",
    "The Akaike Information Criterion (AIC), has the form\n",
    "\n",
    "$\n",
    "\\mbox{AIC} = -2*llf + 2*p,\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### How to use it:\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "where $p$ is the same as the model degrees of freedom. Small values are considered better than large values, so minimizing AIC favors larger likelihoods and simpler models, while trying to balance these two goals.\n",
    "\n",
    "## Bayesian Information Criterion (BIC)\n",
    "\n",
    "The Bayesian Information Criterion (BIC) is related but uses different relative weighting of likelihood and complexity:\n",
    "\n",
    "$\n",
    "\\mbox{BIC} = -2*llf + p*\\log(n).\n",
    "$\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### How to use it:\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "Again, models with smaller values are better than models with larger values. Both methods enforce favoring simpler models among those with simimlar fit overall, and they help prevent overfitting the model because of the complexity penalty.\n",
    "\n",
    "\n",
    "## AIC vs. BIC\n",
    "\n",
    "BIC tends to favor simplicity more heavily than does AIC due to its heavier penalty for large $p$.\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "## What AIC and BIC can be used for:\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Use cases:** AIC and/or BIC are often used to guide variable selection when multiple exogensous variables are considered for inclusion in the model. This enables us to compare a whole series of models and try to find a reasonable tradeoff between bias and variance, i.e., goodness of fit and model complexity. \n",
    "\n",
    "\n",
    "## What AIC and BIC cannot be used for:\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Evaluation of predictive accuracy:**  Although model selection criteria like AIC and BIC can help avoid overfitting and underfitting the data, they do no provide us with assessment of classification performance. In order to evaluate the model selected by these criteria or related strategies, it is still necessary to use some version of the train/test method, where the training data are used for the model building process, and the test data are reserved for predictive evaluation only.\n",
    "\n",
    "\n",
    "<h1 style=\"color:blue;\">Topic 6: Pew Research Survey Example (Model Selection with AIC and BIC)</h1> \n",
    "In the current implementation of the statsmodels logit api, both of these criteria are available from the model fitting results. Here's a summary for our two models of the Pew survey data for predicting favorable or unfavorable opinions of the border wall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>  1465</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  1458</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 19 Nov 2020</td> <th>  Pseudo R-squ.:     </th>   <td>0.2738</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:05:08</td>     <th>  Log-Likelihood:    </th>  <td> -682.88</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -940.37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.971e-108</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                     <td>   -3.5261</td> <td>    0.281</td> <td>  -12.536</td> <td> 0.000</td> <td>   -4.077</td> <td>   -2.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>party[T.Independent]</th>          <td>    1.6843</td> <td>    0.191</td> <td>    8.796</td> <td> 0.000</td> <td>    1.309</td> <td>    2.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>party[T.No preference (VOL.)]</th> <td>    1.8226</td> <td>    0.379</td> <td>    4.807</td> <td> 0.000</td> <td>    1.079</td> <td>    2.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>party[T.Other party (VOL.)]</th>   <td>    2.8930</td> <td>    0.938</td> <td>    3.083</td> <td> 0.002</td> <td>    1.054</td> <td>    4.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>party[T.Republican]</th>           <td>    3.5862</td> <td>    0.206</td> <td>   17.435</td> <td> 0.000</td> <td>    3.183</td> <td>    3.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex[T.Male]</th>                   <td>    0.3721</td> <td>    0.137</td> <td>    2.712</td> <td> 0.007</td> <td>    0.103</td> <td>    0.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                           <td>    0.0168</td> <td>    0.004</td> <td>    4.305</td> <td> 0.000</td> <td>    0.009</td> <td>    0.024</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1465\n",
       "Model:                          Logit   Df Residuals:                     1458\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Thu, 19 Nov 2020   Pseudo R-squ.:                  0.2738\n",
       "Time:                        11:05:08   Log-Likelihood:                -682.88\n",
       "converged:                       True   LL-Null:                       -940.37\n",
       "Covariance Type:            nonrobust   LLR p-value:                4.971e-108\n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "Intercept                        -3.5261      0.281    -12.536      0.000      -4.077      -2.975\n",
       "party[T.Independent]              1.6843      0.191      8.796      0.000       1.309       2.060\n",
       "party[T.No preference (VOL.)]     1.8226      0.379      4.807      0.000       1.079       2.566\n",
       "party[T.Other party (VOL.)]       2.8930      0.938      3.083      0.002       1.054       4.732\n",
       "party[T.Republican]               3.5862      0.206     17.435      0.000       3.183       3.989\n",
       "sex[T.Male]                       0.3721      0.137      2.712      0.007       0.103       0.641\n",
       "age                               0.0168      0.004      4.305      0.000       0.009       0.024\n",
       "=================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>  1465</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1462</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 19 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.03557</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:05:08</td>     <th>  Log-Likelihood:    </th> <td> -906.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -940.37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.960e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>   -2.0818</td> <td>    0.196</td> <td>  -10.637</td> <td> 0.000</td> <td>   -2.465</td> <td>   -1.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex[T.Male]</th> <td>    0.5415</td> <td>    0.114</td> <td>    4.750</td> <td> 0.000</td> <td>    0.318</td> <td>    0.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>         <td>    0.0220</td> <td>    0.003</td> <td>    6.770</td> <td> 0.000</td> <td>    0.016</td> <td>    0.028</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1465\n",
       "Model:                          Logit   Df Residuals:                     1462\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Thu, 19 Nov 2020   Pseudo R-squ.:                 0.03557\n",
       "Time:                        11:05:08   Log-Likelihood:                -906.92\n",
       "converged:                       True   LL-Null:                       -940.37\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.960e-15\n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept      -2.0818      0.196    -10.637      0.000      -2.465      -1.698\n",
       "sex[T.Male]     0.5415      0.114      4.750      0.000       0.318       0.765\n",
       "age             0.0220      0.003      6.770      0.000       0.016       0.028\n",
       "===============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1379.7590888950426,\n",
       " 1819.8364712252783,\n",
       " 1416.7863625452007,\n",
       " 1835.7053027896318)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.aic, model0.aic, model1.bic, model0.bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-2*llf</th>\n",
       "      <th>df_model</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1813.836471</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1819.836471</td>\n",
       "      <td>1835.705303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1365.759089</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1379.759089</td>\n",
       "      <td>1416.786363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        -2*llf  df_model          AIC          BIC\n",
       "0  1813.836471       2.0  1819.836471  1835.705303\n",
       "1  1365.759089       6.0  1379.759089  1416.786363"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'-2*llf': [-2*llf0, -2*llf1], \n",
    "              'df_model': [df0, df1], \n",
    "              'AIC': [model0.aic, model1.aic],\n",
    "              'BIC': [model0.bic, model1.bic]},\n",
    "             index=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "Both AIC and BIC favor Model 1. This suggests that Model 0 is too simple, so the bias due to omitted variables is too large for this model compared to Model 1.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 7: Determining What our Null Model Should Be (Given a Full Model): Backwards Elimination Algorithm</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the features matrix and response data from a logit model\n",
    "\n",
    "For illustration in an example with many explanatory variables we generate binary response data with 20 explanatory variables. First we set up the coefficient vector for the simulation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, bernoulli\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2. ,  2. ,  2. ,  2. ,  2. , -1.5, -1.5, -1.5, -1.5, -1.5,  0.5,\n",
       "        0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make a coefficient vector for logit model\n",
    "b0 = -1  # intercept\n",
    "bvec = np.repeat([2,-1.5,0.5], [5, 5, 10])  # feature coefficients\n",
    "bvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we generate a random features matrix, using numpy matrix operations to form the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a features matrix with n observations \n",
    "# and columns matching the coefficent vector\n",
    "n = 200\n",
    "nX = bvec.size\n",
    "X = norm.rvs(size=n*nX, random_state=1).reshape((n, nX))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641, -0.52817175, ..., -0.87785842,\n",
       "         0.04221375,  0.58281521],\n",
       "       [-1.10061918,  1.14472371,  0.90159072, ...,  0.2344157 ,\n",
       "         1.65980218,  0.74204416],\n",
       "       [-0.19183555, -0.88762896, -0.74715829, ...,  0.93110208,\n",
       "         0.28558733,  0.88514116],\n",
       "       ...,\n",
       "       [ 1.99151525,  1.29962918, -0.59207261, ..., -0.45165125,\n",
       "        -0.52973059,  0.63291748],\n",
       "       [ 0.87499606, -1.04936913, -0.60735181, ..., -0.10561872,\n",
       "        -0.86173477,  0.47313567],\n",
       "       [-0.13888137,  2.65213968, -0.656247  , ..., -0.84391327,\n",
       "         0.62834172,  0.53721449]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use numpy matrix multiplication to form the log-odds model, and exponentiate to get the vector of n odds for the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the odds of 1 for n observations\n",
    "# use numpy matrix multiplication to make this easier\n",
    "odds = np.exp(b0 + np.matmul(X, bvec)) \n",
    "odds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the odds vector to the population probability vector for the n 0/1 responses. Then use the bernoulli.rvs function to generate the responses from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute simulated Bernoulli responses\n",
    "y = bernoulli.rvs(p=odds/(1+odds), size=n, random_state=12347)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up for formula based modeling, we assign names to the columns of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the features names and load X into a data frame\n",
    "Xnames = []\n",
    "for i in range(nX):\n",
    "    list.append(Xnames, 'X'+str(i+1))\n",
    "df = pd.DataFrame(X, columns=Xnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.624345</td>\n",
       "      <td>-0.611756</td>\n",
       "      <td>-0.528172</td>\n",
       "      <td>-1.072969</td>\n",
       "      <td>0.865408</td>\n",
       "      <td>-2.301539</td>\n",
       "      <td>1.744812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100619</td>\n",
       "      <td>1.144724</td>\n",
       "      <td>0.901591</td>\n",
       "      <td>0.502494</td>\n",
       "      <td>0.900856</td>\n",
       "      <td>-0.683728</td>\n",
       "      <td>-0.122890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.191836</td>\n",
       "      <td>-0.887629</td>\n",
       "      <td>-0.747158</td>\n",
       "      <td>1.692455</td>\n",
       "      <td>0.050808</td>\n",
       "      <td>-0.636996</td>\n",
       "      <td>0.190915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.754398</td>\n",
       "      <td>1.252868</td>\n",
       "      <td>0.512930</td>\n",
       "      <td>-0.298093</td>\n",
       "      <td>0.488518</td>\n",
       "      <td>-0.075572</td>\n",
       "      <td>1.131629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.222328</td>\n",
       "      <td>-0.200758</td>\n",
       "      <td>0.186561</td>\n",
       "      <td>0.410052</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>0.119009</td>\n",
       "      <td>-0.670662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7\n",
       "0  1.624345 -0.611756 -0.528172 -1.072969  0.865408 -2.301539  1.744812\n",
       "1 -1.100619  1.144724  0.901591  0.502494  0.900856 -0.683728 -0.122890\n",
       "2 -0.191836 -0.887629 -0.747158  1.692455  0.050808 -0.636996  0.190915\n",
       "3 -0.754398  1.252868  0.512930 -0.298093  0.488518 -0.075572  1.131629\n",
       "4 -0.222328 -0.200758  0.186561  0.410052  0.198300  0.119009 -0.670662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.761207</td>\n",
       "      <td>0.319039</td>\n",
       "      <td>-0.249370</td>\n",
       "      <td>1.462108</td>\n",
       "      <td>-2.060141</td>\n",
       "      <td>-0.322417</td>\n",
       "      <td>-0.384054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.935769</td>\n",
       "      <td>-0.267888</td>\n",
       "      <td>0.530355</td>\n",
       "      <td>-0.691661</td>\n",
       "      <td>-0.396754</td>\n",
       "      <td>-0.687173</td>\n",
       "      <td>-0.845206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.100255</td>\n",
       "      <td>0.120159</td>\n",
       "      <td>0.617203</td>\n",
       "      <td>0.300170</td>\n",
       "      <td>-0.352250</td>\n",
       "      <td>-1.142518</td>\n",
       "      <td>-0.349343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.519817</td>\n",
       "      <td>2.185575</td>\n",
       "      <td>-1.396496</td>\n",
       "      <td>-1.444114</td>\n",
       "      <td>-0.504466</td>\n",
       "      <td>0.160037</td>\n",
       "      <td>0.876169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.377564</td>\n",
       "      <td>0.121821</td>\n",
       "      <td>1.129484</td>\n",
       "      <td>1.198918</td>\n",
       "      <td>0.185156</td>\n",
       "      <td>-0.375285</td>\n",
       "      <td>-0.638730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X8        X9       X10       X11       X12       X13       X14\n",
       "0 -0.761207  0.319039 -0.249370  1.462108 -2.060141 -0.322417 -0.384054\n",
       "1 -0.935769 -0.267888  0.530355 -0.691661 -0.396754 -0.687173 -0.845206\n",
       "2  2.100255  0.120159  0.617203  0.300170 -0.352250 -1.142518 -0.349343\n",
       "3  1.519817  2.185575 -1.396496 -1.444114 -0.504466  0.160037  0.876169\n",
       "4  0.377564  0.121821  1.129484  1.198918  0.185156 -0.375285 -0.638730"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.099891</td>\n",
       "      <td>-0.172428</td>\n",
       "      <td>-0.877858</td>\n",
       "      <td>0.042214</td>\n",
       "      <td>0.582815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012665</td>\n",
       "      <td>-1.117310</td>\n",
       "      <td>0.234416</td>\n",
       "      <td>1.659802</td>\n",
       "      <td>0.742044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.586623</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.931102</td>\n",
       "      <td>0.285587</td>\n",
       "      <td>0.885141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.022201</td>\n",
       "      <td>-0.306204</td>\n",
       "      <td>0.827975</td>\n",
       "      <td>0.230095</td>\n",
       "      <td>0.762011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077340</td>\n",
       "      <td>-0.343854</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>-0.620001</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X16       X17       X18       X19       X20  y\n",
       "0 -1.099891 -0.172428 -0.877858  0.042214  0.582815  0\n",
       "1 -0.012665 -1.117310  0.234416  1.659802  0.742044  1\n",
       "2  0.586623  0.838983  0.931102  0.285587  0.885141  0\n",
       "3 -2.022201 -0.306204  0.827975  0.230095  0.762011  0\n",
       "4  0.077340 -0.343854  0.043597 -0.620001  0.698032  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add y to the data frame\n",
    "df['y'] = y\n",
    "display(df.shape, df.iloc[0:5,:7], \\\n",
    "        df.iloc[0:5, 7:14], df.iloc[0:5, 15:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FOR ASSESSING PREDICTIVE POWER OF NEW OBSERVATIONS: Split the data into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data frame into training data (traindf) \n",
    "# and testing data (testdf)\n",
    "df_train, df_test = train_test_split(\n",
    "    df, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 21), (40, 21))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FOR CREATING A MODEL THAT IS \"PARSIMONIOUS\": Model the training data: are 20 variables necessary?\n",
    "\n",
    "### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176600\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "mod0 = smf.logit(\n",
    "    'y ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10\\\n",
    "    +X11+X12+X13+X14+X15+X16+X17+X18+X19+X20', \n",
    "    data=df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   160</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   139</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    20</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 19 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.7376</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:05:09</td>     <th>  Log-Likelihood:    </th> <td> -28.256</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -107.68</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.251e-23</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model information\n",
    "mod0.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -1.3640</td> <td>    0.504</td> <td>   -2.709</td> <td> 0.007</td> <td>   -2.351</td> <td>   -0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>    2.4668</td> <td>    0.700</td> <td>    3.524</td> <td> 0.000</td> <td>    1.095</td> <td>    3.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    2.5231</td> <td>    0.752</td> <td>    3.355</td> <td> 0.001</td> <td>    1.049</td> <td>    3.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>        <td>    2.6866</td> <td>    0.737</td> <td>    3.645</td> <td> 0.000</td> <td>    1.242</td> <td>    4.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>        <td>    2.1278</td> <td>    0.767</td> <td>    2.773</td> <td> 0.006</td> <td>    0.624</td> <td>    3.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X5</th>        <td>    2.1866</td> <td>    0.618</td> <td>    3.541</td> <td> 0.000</td> <td>    0.976</td> <td>    3.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X6</th>        <td>   -1.3311</td> <td>    0.503</td> <td>   -2.645</td> <td> 0.008</td> <td>   -2.317</td> <td>   -0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X7</th>        <td>   -2.4016</td> <td>    0.653</td> <td>   -3.677</td> <td> 0.000</td> <td>   -3.682</td> <td>   -1.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X8</th>        <td>   -1.6166</td> <td>    0.576</td> <td>   -2.806</td> <td> 0.005</td> <td>   -2.746</td> <td>   -0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X9</th>        <td>   -2.0160</td> <td>    0.710</td> <td>   -2.838</td> <td> 0.005</td> <td>   -3.409</td> <td>   -0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X10</th>       <td>   -2.2436</td> <td>    0.721</td> <td>   -3.112</td> <td> 0.002</td> <td>   -3.657</td> <td>   -0.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X11</th>       <td>    1.4669</td> <td>    0.551</td> <td>    2.660</td> <td> 0.008</td> <td>    0.386</td> <td>    2.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X12</th>       <td>    0.7205</td> <td>    0.432</td> <td>    1.670</td> <td> 0.095</td> <td>   -0.125</td> <td>    1.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X13</th>       <td>    0.8124</td> <td>    0.451</td> <td>    1.802</td> <td> 0.072</td> <td>   -0.071</td> <td>    1.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X14</th>       <td>    0.1165</td> <td>    0.412</td> <td>    0.283</td> <td> 0.777</td> <td>   -0.690</td> <td>    0.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X15</th>       <td>    0.2603</td> <td>    0.459</td> <td>    0.567</td> <td> 0.571</td> <td>   -0.640</td> <td>    1.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X16</th>       <td>    0.6365</td> <td>    0.489</td> <td>    1.302</td> <td> 0.193</td> <td>   -0.321</td> <td>    1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X17</th>       <td>    0.3760</td> <td>    0.392</td> <td>    0.960</td> <td> 0.337</td> <td>   -0.392</td> <td>    1.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X18</th>       <td>   -0.1898</td> <td>    0.545</td> <td>   -0.348</td> <td> 0.728</td> <td>   -1.258</td> <td>    0.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X19</th>       <td>    1.0728</td> <td>    0.477</td> <td>    2.248</td> <td> 0.025</td> <td>    0.137</td> <td>    2.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X20</th>       <td>    0.8356</td> <td>    0.489</td> <td>    1.710</td> <td> 0.087</td> <td>   -0.122</td> <td>    1.793</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model coefficient summary table\n",
    "mod0.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are AIC and BIC for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98.51189376685147, 163.09054388676185)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mod0.aic, mod0.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Backwards Elimination Algorithm Ideas\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Which Null Model Should we Select to Compare to the Full Model?\n",
    "Let's compare a simpler model. There are many possible models ($2^{20}$), so how can we process them? An old idea is to use the coefficient tests to help filter variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X7           0.000236\n",
       "X3           0.000267\n",
       "X5           0.000399\n",
       "X1           0.000425\n",
       "X2           0.000794\n",
       "X10          0.001857\n",
       "X9           0.004545\n",
       "X8           0.005020\n",
       "X4           0.005551\n",
       "Intercept    0.006752\n",
       "X11          0.007813\n",
       "X6           0.008164\n",
       "X19          0.024573\n",
       "X13          0.071623\n",
       "X20          0.087216\n",
       "X12          0.095010\n",
       "X16          0.192819\n",
       "X17          0.337042\n",
       "X15          0.570756\n",
       "X18          0.727601\n",
       "X14          0.777220\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod0.pvalues.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.006752\n",
       "X1           0.000425\n",
       "X2           0.000794\n",
       "X3           0.000267\n",
       "X4           0.005551\n",
       "X5           0.000399\n",
       "X6           0.008164\n",
       "X7           0.000236\n",
       "X8           0.005020\n",
       "X9           0.004545\n",
       "X10          0.001857\n",
       "X11          0.007813\n",
       "X19          0.024573\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod0.pvalues[mod0.pvalues < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Idea: Null Model = Only the Variables that have Statistically Significant p-values in the Full Model\n",
    "Let's compare the model that only keeps these \"significant\" variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227307\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(98.73829394056689, 138.71555353860663)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1 = smf.logit(\n",
    "    'y ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X19', \n",
    "    data=df_train).fit()\n",
    "(mod1.aic, mod1.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIC is reduced. AIC is about the same. Let's try to go further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.010066\n",
       "X1           0.000045\n",
       "X2           0.000043\n",
       "X3           0.000013\n",
       "X4           0.000229\n",
       "X5           0.000192\n",
       "X6           0.008512\n",
       "X7           0.000085\n",
       "X8           0.000584\n",
       "X9           0.000647\n",
       "X10          0.000220\n",
       "X11          0.002939\n",
       "X19          0.023514\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1.pvalues[mod1.pvalues < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Idea: Null Model = Drop Even More Explanatory Variables, Starting with the Ones that Have the Highest p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X19    0.023514\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# least significant variable in mod1\n",
    "mod1.pvalues[mod1.pvalues==max(mod1.pvalues)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try dropping this least significant variable to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.245458\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(102.5466613953034, 139.44874717810933)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2 = smf.logit('y ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11', \n",
    "                 data=df_train).fit()\n",
    "(mod2.aic, mod2.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIC and BIC increase a bit. Try dropping one more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.013388\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2.pvalues[mod2.pvalues==max(mod2.pvalues)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X3           0.000015\n",
       "X2           0.000018\n",
       "X1           0.000032\n",
       "X7           0.000081\n",
       "X5           0.000210\n",
       "X10          0.000236\n",
       "X4           0.000363\n",
       "X8           0.000818\n",
       "X9           0.001048\n",
       "X11          0.005432\n",
       "X6           0.008977\n",
       "Intercept    0.013388\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2.pvalues.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we drop X6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.297416\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(115.17324407941844, 145.9249822317567)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod3 = smf.logit('y ~ X1+X2+X3+X4+X5+X7+X8+X9+X10', \n",
    "                 data=df_train).fit()\n",
    "(mod3.aic, mod3.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more increase. Looks like we can't reduce the model beyond mod1, based on these criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aic</th>\n",
       "      <th>bic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.511894</td>\n",
       "      <td>163.090544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.738294</td>\n",
       "      <td>138.715554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.546661</td>\n",
       "      <td>139.448747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.173244</td>\n",
       "      <td>145.924982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aic         bic\n",
       "0   98.511894  163.090544\n",
       "1   98.738294  138.715554\n",
       "2  102.546661  139.448747\n",
       "3  115.173244  145.924982"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize results\n",
    "pd.DataFrame({'aic': [mod0.aic, mod1.aic, mod2.aic, mod3.aic],\n",
    "             'bic': [mod0.bic, mod1.bic, mod2.bic, mod3.bic] }, \n",
    "             index=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "According to BIC, model 1 is the best. According to AIC it's very close between mod0 and mod1. Here's the model summary for mod1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   160</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   147</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 19 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.6623</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:05:09</td>     <th>  Log-Likelihood:    </th> <td> -36.369</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -107.68</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.766e-24</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.9374</td> <td>    0.364</td> <td>   -2.574</td> <td> 0.010</td> <td>   -1.651</td> <td>   -0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>    2.1566</td> <td>    0.529</td> <td>    4.080</td> <td> 0.000</td> <td>    1.120</td> <td>    3.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    2.0498</td> <td>    0.501</td> <td>    4.090</td> <td> 0.000</td> <td>    1.068</td> <td>    3.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>        <td>    1.9472</td> <td>    0.447</td> <td>    4.358</td> <td> 0.000</td> <td>    1.071</td> <td>    2.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>        <td>    1.7873</td> <td>    0.485</td> <td>    3.685</td> <td> 0.000</td> <td>    0.837</td> <td>    2.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X5</th>        <td>    1.4869</td> <td>    0.399</td> <td>    3.729</td> <td> 0.000</td> <td>    0.705</td> <td>    2.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X6</th>        <td>   -0.9173</td> <td>    0.349</td> <td>   -2.631</td> <td> 0.009</td> <td>   -1.601</td> <td>   -0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X7</th>        <td>   -1.9646</td> <td>    0.500</td> <td>   -3.930</td> <td> 0.000</td> <td>   -2.944</td> <td>   -0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X8</th>        <td>   -1.4560</td> <td>    0.423</td> <td>   -3.439</td> <td> 0.001</td> <td>   -2.286</td> <td>   -0.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X9</th>        <td>   -1.7072</td> <td>    0.500</td> <td>   -3.411</td> <td> 0.001</td> <td>   -2.688</td> <td>   -0.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X10</th>       <td>   -1.7636</td> <td>    0.477</td> <td>   -3.695</td> <td> 0.000</td> <td>   -2.699</td> <td>   -0.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X11</th>       <td>    1.1117</td> <td>    0.374</td> <td>    2.974</td> <td> 0.003</td> <td>    0.379</td> <td>    1.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X19</th>       <td>    0.7941</td> <td>    0.351</td> <td>    2.265</td> <td> 0.024</td> <td>    0.107</td> <td>    1.481</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  160\n",
       "Model:                          Logit   Df Residuals:                      147\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Thu, 19 Nov 2020   Pseudo R-squ.:                  0.6623\n",
       "Time:                        11:05:09   Log-Likelihood:                -36.369\n",
       "converged:                       True   LL-Null:                       -107.68\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.766e-24\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.9374      0.364     -2.574      0.010      -1.651      -0.223\n",
       "X1             2.1566      0.529      4.080      0.000       1.120       3.193\n",
       "X2             2.0498      0.501      4.090      0.000       1.068       3.032\n",
       "X3             1.9472      0.447      4.358      0.000       1.071       2.823\n",
       "X4             1.7873      0.485      3.685      0.000       0.837       2.738\n",
       "X5             1.4869      0.399      3.729      0.000       0.705       2.268\n",
       "X6            -0.9173      0.349     -2.631      0.009      -1.601      -0.234\n",
       "X7            -1.9646      0.500     -3.930      0.000      -2.944      -0.985\n",
       "X8            -1.4560      0.423     -3.439      0.001      -2.286      -0.626\n",
       "X9            -1.7072      0.500     -3.411      0.001      -2.688      -0.726\n",
       "X10           -1.7636      0.477     -3.695      0.000      -2.699      -0.828\n",
       "X11            1.1117      0.374      2.974      0.003       0.379       1.844\n",
       "X19            0.7941      0.351      2.265      0.024       0.107       1.481\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the simulation model that generated the data we see that the best fitted model is missing X8 and includes X14, which we know to have a zero coefficient from the simulation model. This is an example of the effects of sample variation in model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate selected model as a classifier on test data\n",
    "\n",
    "Let's compute the accuracies of the models as classifiers. We'll use the predictive probability as the classification score use the classification rule:\n",
    "\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{cases}\n",
    "1, & \\text{if } \\hat{p} \\ge 0.5\\\\ \n",
    "0, & \\text{if } \\hat{p} \\lt 0.5\\\\\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the predictive probabilities for Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95     0.347583\n",
       "15     0.050317\n",
       "30     0.001393\n",
       "158    0.999849\n",
       "128    0.016493\n",
       "115    0.001555\n",
       "69     0.000541\n",
       "170    0.000013\n",
       "174    0.020079\n",
       "45     0.079501\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat1 = mod1.predict(exog=df_test)\n",
    "phat1[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Statistic Assessing Predictive Power: Classification Accuracy\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### Classification Accuracy for Model 1\n",
    "Here's a function to compute the classification accuracy, which is the overall fraction correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pthresh = 0.5\n",
    "accuracy_score(y_true=df_test['y'], \n",
    "               y_pred=1*(phat1 >= pthresh), \n",
    "               normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification accuracy for Model 1 is estimated to be 92.5%. This is the combination of the true positives rate and the true negatives rate, if we view 1's as positive and 0's as negative. \n",
    "\n",
    "\n",
    "#### Comparing Classification accuracy for all Models?\n",
    "\n",
    "How does this compare to the other models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 40)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bind together all the predictive probabilities into a matrix\n",
    "phat_matrix = np.array([mod0.predict(exog=df_test),\n",
    "                       mod1.predict(exog=df_test),\n",
    "                       mod2.predict(exog=df_test),\n",
    "                       mod3.predict(exog=df_test)])\n",
    "phat_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.09116764e-01, 1.02689627e-01, 1.21609512e-03, 9.99795672e-01,\n",
       "       1.93365814e-02, 6.22526164e-03, 6.48536897e-04, 1.61225639e-05,\n",
       "       2.16677944e-02, 8.21426220e-02])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat_matrix[2][0:10]  # compare with values above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for i in range(0,4):\n",
    "    accuracy_list.append(\n",
    "        accuracy_score(y_true=df_test['y'], \n",
    "                       y_pred=1*(phat_matrix[i] >= pthresh), \n",
    "                       normalize=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.875, 0.925, 0.875, 0.875]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aic</th>\n",
       "      <th>bic</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.511894</td>\n",
       "      <td>163.090544</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.738294</td>\n",
       "      <td>138.715554</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.546661</td>\n",
       "      <td>139.448747</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.173244</td>\n",
       "      <td>145.924982</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aic         bic  accuracy\n",
       "0   98.511894  163.090544     0.875\n",
       "1   98.738294  138.715554     0.925\n",
       "2  102.546661  139.448747     0.875\n",
       "3  115.173244  145.924982     0.875"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'aic': [mod0.aic, mod1.aic, mod2.aic, mod3.aic],\n",
    "             'bic': [mod0.bic, mod1.bic, mod2.bic, mod3.bic],\n",
    "             'accuracy': accuracy_list}, \n",
    "             index=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion using Classification Accuracy\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "For this test set there is no much difference between these models in tersm of classification accuracy, though the model with smallest AIC had the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Predictive Power Statistics: Sensitivity, specificity\n",
    "\n",
    "Accuracy is a blunt measure that depends on the overall fraction of each category as well as the sensitivity and specificity. We can break out the component sensitivity and specificity as illustrated in th previous section. \n",
    "\n",
    "Here's a function used in the previous section for that purpose, modified to include accuracy, and to return a single row data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senspec(y, score, thresh, index=0):\n",
    "    yhat = 1*(score >= thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y, y_pred=yhat).ravel()\n",
    "    sens = tp / (fn + tp)\n",
    "    spec = tn / (fp + tn)\n",
    "    accuracy = (tn+tp)/(tn+fp+fn+tp)\n",
    "    return pd.DataFrame({'tn':[tn], \n",
    "                         'fp':[fp], \n",
    "                         'fn':[fn], \n",
    "                         'tp':[tp], \n",
    "                         'sens':[sens], \n",
    "                         'spec':[spec],\n",
    "                         'accuracy':[accuracy]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tn  fp  fn  tp      sens      spec  accuracy\n",
       "0  22   1   4  13  0.764706  0.956522     0.875"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivy and specificity for Model 0\n",
    "senspec(df_test['y'], phat_matrix[0], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tn  fp  fn  tp      sens      spec  accuracy\n",
       "0  22   1   4  13  0.764706  0.956522     0.875\n",
       "1  23   0   3  14  0.823529  1.000000     0.925\n",
       "2  22   1   4  13  0.764706  0.956522     0.875\n",
       "3  22   1   4  13  0.764706  0.956522     0.875"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity and specificity for all four models\n",
    "perf = senspec(df_test['y'], phat_matrix[0], 0.5)\n",
    "for i in range(1,4):\n",
    "    temp = perf.append(senspec(df_test['y'], phat_matrix[i], 0.5), \n",
    "                       ignore_index=True)\n",
    "    perf = temp\n",
    "perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison Using Sensitivity, Specificity, and Accuracy for all 4 Models.\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "The accuracy, sensitivity and specificity are all better for Model 1 (minimum BIC model) versus the others.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark on the selection of variables\n",
    "\n",
    "From the simulation model we know that all 20 variables had some nonzero population coefficients, so why are some not significant? And why are they removed by the AIC/BIC criteria?\n",
    "\n",
    "+ First, note that the effect sizes for variables X11-X20 are small compared to the effects of X1-X10. With the sample size of 200, small effects often are not statistically significant due to the large standard errors compared to the estimates. We don't have enough power to detect those small effects.\n",
    "\n",
    "\n",
    "+ Second, the predictive performance of the model can be sometimes be improved by removing seemingly significant variables due to the reduced burden of estimation. Having fewer coefficients to estimate can decrease variance and improve mean square error for prediction as long as we retain enough highly informative variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "STAT 207, Victoria Ellison and Douglas Simpson, University of Illinois at Urbana-Champaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
