{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--# STAT 207: Data Science Exploration-->\n",
    "<h1 style=\"color:blue;\">Unit 15: Machine Learning, Regularized Logistic Regression, and Cross-Validation</h1>\n",
    "\n",
    "<h1 style=\"color:blue;\">Topic 1: Introduction to Regularized Logistic Regression</h1> \n",
    "\n",
    "## Review of Methods (we already learned) to Select the \"Best\" Explanatory Variables in a Logistic Regression\n",
    "\n",
    "#### What methods have we learned so far that allow for us to select the \"best\" explanatory variables in a model? How do we define \"best\" in each of these methods?\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### What is a common downside of each of these methods?\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## Main Idea of Regularized Regression\n",
    "\n",
    "#### Main difference between regularized regression vs. regression?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Regularized regression methods are designed to improve modeling of high dimensional data by incorporating a penalty function to drive variable selection. The Python Scikit-Learn library includes regularized regression and regularized logistic regression as standard model optimization methods. This section will provide a brief overview of penalized logistic regression and demonstrate how the methods work on simulated data. \n",
    "\n",
    "\n",
    "<h1 style=\"color:blue;\">Topic 2: Introduction to Cross-Validation</h1> \n",
    "\n",
    "\n",
    "## Review of Methods (we already learned) to Evaluate Classification Accuracy of \"New Data\" with Regression Models\n",
    "\n",
    "#### What methods have we learned so far that allow for us to evaluate the classification accuracy of \"new data\" in logistic regression models?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "#### What is a downside of this method?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## Main Idea of Cross-Validation\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "In order to evaluate the classification accuracy of regularized logistic regression we can use the \n",
    "Train/Test method to avoid optimistic bias. One limitation is that it uses only part of the data for both model building and for assessment.\n",
    "\n",
    "An extension of simple Train/Test is **cross-validation.** This method uses all of the data by repeated application of train/test splitting. The results are then averaged to improve the accuracy. The approach also gives us a simple way to estimate the uncertainty of the accuracy estimate.\n",
    "\n",
    "## Common Types of Cross-Validation\n",
    "\n",
    "### <u>Type 1</u>: Leave-One-Out Cross-Validation\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "The oldest such method is **leave-one-out cross-validation**, where each of the $n$ observations in a sample is omitted in turn. The estimate is recomputed for each of the $n$ subsets of size $n-1$. The resulting $n$ predictions are then used to estimate predictive accuracy.\n",
    "\n",
    "### <u> Type 2</u>: k-Fold Cross-Validation\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Modern methods use **k-fold cross-validation**, where the data are split into $k$ subsets. $k-1$ subsets are used for training, and the left out subset is used for testing. This is repeated at least $k$ times, leaving out each of the $k$ subsets in turn. \n",
    "\n",
    "The random selection of the $k$ subsets can itself be repeated to generate multiple $k$ fold splits, thus avoiding over dependence on one particular random split.\n",
    "\n",
    "To use these methods efficiently in Python, we first discuss the structure of models in the machine learning library Scikit-Learn. Then we illustrate some of the cross validation capabilities in the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 3: Introduction to Machine Learning</h1> \n",
    "\n",
    "## 3a: Model building with Scikit-Learn Package (as opposed to statsmodels package)\n",
    "\n",
    "#### Regularized Logistic Regression is a type of machine learning algorithm. In order to build a *regularized* logistic regression model, we need to use a different Python package.\n",
    "\n",
    "#### Libraries and modules\n",
    "\n",
    "    pandas, numpy\n",
    "    matplotlib.pyplot\n",
    "    seaborn\n",
    "        heatmap\n",
    "    scipy.stats\n",
    "        norm, bernoulli\n",
    "    sklearn.linear_model\n",
    "        LogisticRegression\n",
    "    sklearn.model_selection\n",
    "        train_test_split\n",
    "    sklearn.metrics\n",
    "        confusion_matrix\n",
    "        roc_curve, roc_auc_score\n",
    "        cross_val_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the difference in the type of data that <u>statsmodel package</u> uses vs. the type of data that <u>scikit-learn package</u>  uses?\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the statsmodels API, which is formula based and operates on pandas data frames, the machine learning functions in the Scikit-Learn expect data to be encoded as numerical matrices. \n",
    "\n",
    "## Machine Learning Definitions: Two Main Matrices\n",
    "\n",
    "### Features Matrix\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "The **features matrix $X$** is an array with $n$ rows of observations and $p$ columns of features (explanatory variables);\n",
    "\n",
    "We can think of the features matrix as a data frame containing only explanatory variables. Sci-kit learn modules generally expect $X$ to contain only numerical columns. Therefore it provides preprocessing functions to\n",
    "\n",
    "+ Convert categorical and boolean data into numerically coded columns (e.g. 0/1 indicator columns)\n",
    "\n",
    "\n",
    "+ Add a column of 1s for the intercept if desired (fit_intercept=True -- in sklearn.linear_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Target Array\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "The **target array** $y$ is an array with elements that serve as \"labels\" for the $n$ observations.\n",
    "\n",
    "\n",
    "**Target array $y$:** This is our array of labels, i.e., response data that will be used to train the model. It may be categorical (0/1) as in classification problems and logistic regression, or have continuous numerical values as in linear regression.\n",
    "\n",
    "### How to convert columns from a dataframe to a features matrix X and a target array y?\n",
    "\n",
    "Given a data frame containing both X and y data, we'll need to extract these two arrays from the data frame. We'll see a simple way to do this using Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b: Two Main Types of Machine Learning\n",
    "\n",
    "#### What is the main difference between <u>supervised learning</u> vs. <u>unsupervised learning</u>?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### **Supervised learning**:\n",
    "\n",
    "#### Nature of the Data You Have with Supervised Learning\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "When we have a target array $y$, its elements **label** the corresponding rows of $X$. \n",
    "\n",
    "#### Types of Supervised Learning Labels\n",
    "\n",
    "The two main types of labels are:\n",
    "\n",
    "1. **Categorical (0/1) labels:** these correspond to **classification problems**, where the labels are said to **supervise** the modeling of how information in $X$ can be used for training the classifier.\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "2. **Continuous numerical labels:** these correspond to **predictive regression problems** such as linear regresssion or regularized regresssion, where the goal is to predict numerical responses. The numerical $y$ labels **supervise** training of the regression model, e.g., by minimizing and ordinary or penalized least squares criterion.\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### General Goal of Supervised Learning\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning\n",
    "\n",
    "#### Nature of the Data You Have with Unsupervised Learning\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### General Goal of Unsupervised Learning\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### Common Types of Unsupervised Learning Algorithms\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "If we have unlabeled data, so $y$ is not available, we can no longer classify the rows of $X$, however, it is often of interest to detect **clusters** of samples in $X$ based on some assumptions about how subpopulations might separate. Applications include $k$-means clustering and mixtures of Gaussian distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c: General Modeling steps in the modeling/machine learning process\n",
    "This section focuses on supervised model building, and, at the end, generalizing train/test methods to k-fold cross-validation.\n",
    "\n",
    "Scikit-Learn are designed to faciliate a regular sequence of modeling steps:\n",
    "\n",
    "#### <u>Step 1</u>: Choose the model class for the problem and import the Scikit-Learn estimator class\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "#### <u>Step 2</u>: Choose model hyperparameters to create an instance of the class (more later)\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### <u>Step 3</u>: Organize data into the features matrix $X$ and target array $y$\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### <u>Step 4</u>: Train the model using the .fit() method\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### <u>Step 5</u>: Test the model on new or test data using the .predict() method\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### <u>Step 6</u>:Compute performance metrics, e.g., using the .score( ) method\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "For extensive further discussion, see VanDerPlas, Chapter 5. We cover the basics with some examples here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 4: Descriptive Analytics for Datasets with a Large Amount of Explanatory Variables (ie. High Dimensional Datasets)</h1> \n",
    "\n",
    "## Data Simulation Generation: with 20 features (explanatory variables) and binary target (response variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate our simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## make a coefficient vector for logit model\n",
    "b0 = -1  # intercept\n",
    "bvec = np.repeat([1,-1,0], [5, 5, 10])  # feature coefficients\n",
    "n = 200\n",
    "nX = bvec.size\n",
    "\n",
    "Xmat = norm.rvs(size=n*nX, random_state=1).reshape((n, nX))\n",
    "# Generate X and add the column names\n",
    "##X = pd.DataFrame(\n",
    "##    norm.rvs(size=n*nX, random_state=1).reshape((n, nX)), \n",
    "##    columns=Xnames)\n",
    "# Now generate the target array using X and the coefficient vector\n",
    "odds = np.exp(b0 + np.matmul(Xmat, bvec)) # use matrix multiplication\n",
    "gen_y = bernoulli.rvs(p=odds/(1+odds), size=n, random_state=12347)\n",
    "# load X into data frame with names\n",
    "Xnames = []\n",
    "for i in range(nX):\n",
    "    list.append(Xnames, 'X'+str(i+1))\n",
    "gen_X = pd.DataFrame(Xmat, columns=Xnames)\n",
    "display(gen_X.shape, gen_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe version of our Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.624345</td>\n",
       "      <td>-0.611756</td>\n",
       "      <td>-0.528172</td>\n",
       "      <td>-1.072969</td>\n",
       "      <td>0.865408</td>\n",
       "      <td>-2.301539</td>\n",
       "      <td>1.744812</td>\n",
       "      <td>-0.761207</td>\n",
       "      <td>0.319039</td>\n",
       "      <td>-0.249370</td>\n",
       "      <td>1.462108</td>\n",
       "      <td>-2.060141</td>\n",
       "      <td>-0.322417</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>1.133769</td>\n",
       "      <td>-1.099891</td>\n",
       "      <td>-0.172428</td>\n",
       "      <td>-0.877858</td>\n",
       "      <td>0.042214</td>\n",
       "      <td>0.582815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100619</td>\n",
       "      <td>1.144724</td>\n",
       "      <td>0.901591</td>\n",
       "      <td>0.502494</td>\n",
       "      <td>0.900856</td>\n",
       "      <td>-0.683728</td>\n",
       "      <td>-0.122890</td>\n",
       "      <td>-0.935769</td>\n",
       "      <td>-0.267888</td>\n",
       "      <td>0.530355</td>\n",
       "      <td>-0.691661</td>\n",
       "      <td>-0.396754</td>\n",
       "      <td>-0.687173</td>\n",
       "      <td>-0.845206</td>\n",
       "      <td>-0.671246</td>\n",
       "      <td>-0.012665</td>\n",
       "      <td>-1.117310</td>\n",
       "      <td>0.234416</td>\n",
       "      <td>1.659802</td>\n",
       "      <td>0.742044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.191836</td>\n",
       "      <td>-0.887629</td>\n",
       "      <td>-0.747158</td>\n",
       "      <td>1.692455</td>\n",
       "      <td>0.050808</td>\n",
       "      <td>-0.636996</td>\n",
       "      <td>0.190915</td>\n",
       "      <td>2.100255</td>\n",
       "      <td>0.120159</td>\n",
       "      <td>0.617203</td>\n",
       "      <td>0.300170</td>\n",
       "      <td>-0.352250</td>\n",
       "      <td>-1.142518</td>\n",
       "      <td>-0.349343</td>\n",
       "      <td>-0.208894</td>\n",
       "      <td>0.586623</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.931102</td>\n",
       "      <td>0.285587</td>\n",
       "      <td>0.885141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.754398</td>\n",
       "      <td>1.252868</td>\n",
       "      <td>0.512930</td>\n",
       "      <td>-0.298093</td>\n",
       "      <td>0.488518</td>\n",
       "      <td>-0.075572</td>\n",
       "      <td>1.131629</td>\n",
       "      <td>1.519817</td>\n",
       "      <td>2.185575</td>\n",
       "      <td>-1.396496</td>\n",
       "      <td>-1.444114</td>\n",
       "      <td>-0.504466</td>\n",
       "      <td>0.160037</td>\n",
       "      <td>0.876169</td>\n",
       "      <td>0.315635</td>\n",
       "      <td>-2.022201</td>\n",
       "      <td>-0.306204</td>\n",
       "      <td>0.827975</td>\n",
       "      <td>0.230095</td>\n",
       "      <td>0.762011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.222328</td>\n",
       "      <td>-0.200758</td>\n",
       "      <td>0.186561</td>\n",
       "      <td>0.410052</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>0.119009</td>\n",
       "      <td>-0.670662</td>\n",
       "      <td>0.377564</td>\n",
       "      <td>0.121821</td>\n",
       "      <td>1.129484</td>\n",
       "      <td>1.198918</td>\n",
       "      <td>0.185156</td>\n",
       "      <td>-0.375285</td>\n",
       "      <td>-0.638730</td>\n",
       "      <td>0.423494</td>\n",
       "      <td>0.077340</td>\n",
       "      <td>-0.343854</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>-0.620001</td>\n",
       "      <td>0.698032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.298112</td>\n",
       "      <td>-0.132637</td>\n",
       "      <td>-2.251077</td>\n",
       "      <td>2.893593</td>\n",
       "      <td>2.742155</td>\n",
       "      <td>-0.510218</td>\n",
       "      <td>0.833351</td>\n",
       "      <td>0.088922</td>\n",
       "      <td>0.253389</td>\n",
       "      <td>0.343292</td>\n",
       "      <td>1.073503</td>\n",
       "      <td>-0.669049</td>\n",
       "      <td>0.715354</td>\n",
       "      <td>0.707662</td>\n",
       "      <td>-2.548717</td>\n",
       "      <td>1.468340</td>\n",
       "      <td>0.657419</td>\n",
       "      <td>-0.582217</td>\n",
       "      <td>0.047880</td>\n",
       "      <td>0.512468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.284319</td>\n",
       "      <td>0.525410</td>\n",
       "      <td>-2.050876</td>\n",
       "      <td>0.211909</td>\n",
       "      <td>1.110508</td>\n",
       "      <td>0.751354</td>\n",
       "      <td>0.217867</td>\n",
       "      <td>-0.780517</td>\n",
       "      <td>0.070358</td>\n",
       "      <td>-1.186303</td>\n",
       "      <td>0.120607</td>\n",
       "      <td>-0.174415</td>\n",
       "      <td>0.499442</td>\n",
       "      <td>1.388842</td>\n",
       "      <td>0.850542</td>\n",
       "      <td>-0.831536</td>\n",
       "      <td>-0.967498</td>\n",
       "      <td>-0.865728</td>\n",
       "      <td>-0.870450</td>\n",
       "      <td>-1.038534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.991515</td>\n",
       "      <td>1.299629</td>\n",
       "      <td>-0.592073</td>\n",
       "      <td>0.049659</td>\n",
       "      <td>2.478005</td>\n",
       "      <td>-1.778695</td>\n",
       "      <td>0.395753</td>\n",
       "      <td>2.003272</td>\n",
       "      <td>0.148823</td>\n",
       "      <td>-0.551342</td>\n",
       "      <td>1.269868</td>\n",
       "      <td>2.260748</td>\n",
       "      <td>-0.182916</td>\n",
       "      <td>1.193456</td>\n",
       "      <td>-0.959332</td>\n",
       "      <td>0.263967</td>\n",
       "      <td>0.639034</td>\n",
       "      <td>-0.451651</td>\n",
       "      <td>-0.529731</td>\n",
       "      <td>0.632917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.874996</td>\n",
       "      <td>-1.049369</td>\n",
       "      <td>-0.607352</td>\n",
       "      <td>0.418138</td>\n",
       "      <td>-1.541780</td>\n",
       "      <td>-1.025194</td>\n",
       "      <td>0.325975</td>\n",
       "      <td>0.805144</td>\n",
       "      <td>0.273739</td>\n",
       "      <td>-0.075940</td>\n",
       "      <td>1.682478</td>\n",
       "      <td>0.202187</td>\n",
       "      <td>-0.527962</td>\n",
       "      <td>-2.071264</td>\n",
       "      <td>0.526165</td>\n",
       "      <td>-0.450283</td>\n",
       "      <td>-0.348754</td>\n",
       "      <td>-0.105619</td>\n",
       "      <td>-0.861735</td>\n",
       "      <td>0.473136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-0.138881</td>\n",
       "      <td>2.652140</td>\n",
       "      <td>-0.656247</td>\n",
       "      <td>0.279562</td>\n",
       "      <td>-0.607715</td>\n",
       "      <td>0.729814</td>\n",
       "      <td>-0.887188</td>\n",
       "      <td>0.077327</td>\n",
       "      <td>0.073416</td>\n",
       "      <td>0.416026</td>\n",
       "      <td>-1.879200</td>\n",
       "      <td>0.575459</td>\n",
       "      <td>0.102062</td>\n",
       "      <td>1.184304</td>\n",
       "      <td>-0.794843</td>\n",
       "      <td>-0.125903</td>\n",
       "      <td>-0.960346</td>\n",
       "      <td>-0.843913</td>\n",
       "      <td>0.628342</td>\n",
       "      <td>0.537214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0    1.624345 -0.611756 -0.528172 -1.072969  0.865408 -2.301539  1.744812   \n",
       "1   -1.100619  1.144724  0.901591  0.502494  0.900856 -0.683728 -0.122890   \n",
       "2   -0.191836 -0.887629 -0.747158  1.692455  0.050808 -0.636996  0.190915   \n",
       "3   -0.754398  1.252868  0.512930 -0.298093  0.488518 -0.075572  1.131629   \n",
       "4   -0.222328 -0.200758  0.186561  0.410052  0.198300  0.119009 -0.670662   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.298112 -0.132637 -2.251077  2.893593  2.742155 -0.510218  0.833351   \n",
       "196 -0.284319  0.525410 -2.050876  0.211909  1.110508  0.751354  0.217867   \n",
       "197  1.991515  1.299629 -0.592073  0.049659  2.478005 -1.778695  0.395753   \n",
       "198  0.874996 -1.049369 -0.607352  0.418138 -1.541780 -1.025194  0.325975   \n",
       "199 -0.138881  2.652140 -0.656247  0.279562 -0.607715  0.729814 -0.887188   \n",
       "\n",
       "           X8        X9       X10       X11       X12       X13       X14  \\\n",
       "0   -0.761207  0.319039 -0.249370  1.462108 -2.060141 -0.322417 -0.384054   \n",
       "1   -0.935769 -0.267888  0.530355 -0.691661 -0.396754 -0.687173 -0.845206   \n",
       "2    2.100255  0.120159  0.617203  0.300170 -0.352250 -1.142518 -0.349343   \n",
       "3    1.519817  2.185575 -1.396496 -1.444114 -0.504466  0.160037  0.876169   \n",
       "4    0.377564  0.121821  1.129484  1.198918  0.185156 -0.375285 -0.638730   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.088922  0.253389  0.343292  1.073503 -0.669049  0.715354  0.707662   \n",
       "196 -0.780517  0.070358 -1.186303  0.120607 -0.174415  0.499442  1.388842   \n",
       "197  2.003272  0.148823 -0.551342  1.269868  2.260748 -0.182916  1.193456   \n",
       "198  0.805144  0.273739 -0.075940  1.682478  0.202187 -0.527962 -2.071264   \n",
       "199  0.077327  0.073416  0.416026 -1.879200  0.575459  0.102062  1.184304   \n",
       "\n",
       "          X15       X16       X17       X18       X19       X20  \n",
       "0    1.133769 -1.099891 -0.172428 -0.877858  0.042214  0.582815  \n",
       "1   -0.671246 -0.012665 -1.117310  0.234416  1.659802  0.742044  \n",
       "2   -0.208894  0.586623  0.838983  0.931102  0.285587  0.885141  \n",
       "3    0.315635 -2.022201 -0.306204  0.827975  0.230095  0.762011  \n",
       "4    0.423494  0.077340 -0.343854  0.043597 -0.620001  0.698032  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "195 -2.548717  1.468340  0.657419 -0.582217  0.047880  0.512468  \n",
       "196  0.850542 -0.831536 -0.967498 -0.865728 -0.870450 -1.038534  \n",
       "197 -0.959332  0.263967  0.639034 -0.451651 -0.529731  0.632917  \n",
       "198  0.526165 -0.450283 -0.348754 -0.105619 -0.861735  0.473136  \n",
       "199 -0.794843 -0.125903 -0.960346 -0.843913  0.628342  0.537214  \n",
       "\n",
       "[200 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Version of our Target Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put it all together in df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bundle into a data frame for the purpose of this example. Then we demonstrate how to extract the features matrix X and target y from a data frame in general, for any data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.624345</td>\n",
       "      <td>-0.611756</td>\n",
       "      <td>-0.528172</td>\n",
       "      <td>-1.072969</td>\n",
       "      <td>0.865408</td>\n",
       "      <td>-2.301539</td>\n",
       "      <td>1.744812</td>\n",
       "      <td>-0.761207</td>\n",
       "      <td>0.319039</td>\n",
       "      <td>-0.249370</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.060141</td>\n",
       "      <td>-0.322417</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>1.133769</td>\n",
       "      <td>-1.099891</td>\n",
       "      <td>-0.172428</td>\n",
       "      <td>-0.877858</td>\n",
       "      <td>0.042214</td>\n",
       "      <td>0.582815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100619</td>\n",
       "      <td>1.144724</td>\n",
       "      <td>0.901591</td>\n",
       "      <td>0.502494</td>\n",
       "      <td>0.900856</td>\n",
       "      <td>-0.683728</td>\n",
       "      <td>-0.122890</td>\n",
       "      <td>-0.935769</td>\n",
       "      <td>-0.267888</td>\n",
       "      <td>0.530355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396754</td>\n",
       "      <td>-0.687173</td>\n",
       "      <td>-0.845206</td>\n",
       "      <td>-0.671246</td>\n",
       "      <td>-0.012665</td>\n",
       "      <td>-1.117310</td>\n",
       "      <td>0.234416</td>\n",
       "      <td>1.659802</td>\n",
       "      <td>0.742044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.191836</td>\n",
       "      <td>-0.887629</td>\n",
       "      <td>-0.747158</td>\n",
       "      <td>1.692455</td>\n",
       "      <td>0.050808</td>\n",
       "      <td>-0.636996</td>\n",
       "      <td>0.190915</td>\n",
       "      <td>2.100255</td>\n",
       "      <td>0.120159</td>\n",
       "      <td>0.617203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.352250</td>\n",
       "      <td>-1.142518</td>\n",
       "      <td>-0.349343</td>\n",
       "      <td>-0.208894</td>\n",
       "      <td>0.586623</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.931102</td>\n",
       "      <td>0.285587</td>\n",
       "      <td>0.885141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.754398</td>\n",
       "      <td>1.252868</td>\n",
       "      <td>0.512930</td>\n",
       "      <td>-0.298093</td>\n",
       "      <td>0.488518</td>\n",
       "      <td>-0.075572</td>\n",
       "      <td>1.131629</td>\n",
       "      <td>1.519817</td>\n",
       "      <td>2.185575</td>\n",
       "      <td>-1.396496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504466</td>\n",
       "      <td>0.160037</td>\n",
       "      <td>0.876169</td>\n",
       "      <td>0.315635</td>\n",
       "      <td>-2.022201</td>\n",
       "      <td>-0.306204</td>\n",
       "      <td>0.827975</td>\n",
       "      <td>0.230095</td>\n",
       "      <td>0.762011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.222328</td>\n",
       "      <td>-0.200758</td>\n",
       "      <td>0.186561</td>\n",
       "      <td>0.410052</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>0.119009</td>\n",
       "      <td>-0.670662</td>\n",
       "      <td>0.377564</td>\n",
       "      <td>0.121821</td>\n",
       "      <td>1.129484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185156</td>\n",
       "      <td>-0.375285</td>\n",
       "      <td>-0.638730</td>\n",
       "      <td>0.423494</td>\n",
       "      <td>0.077340</td>\n",
       "      <td>-0.343854</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>-0.620001</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0  1.624345 -0.611756 -0.528172 -1.072969  0.865408 -2.301539  1.744812   \n",
       "1 -1.100619  1.144724  0.901591  0.502494  0.900856 -0.683728 -0.122890   \n",
       "2 -0.191836 -0.887629 -0.747158  1.692455  0.050808 -0.636996  0.190915   \n",
       "3 -0.754398  1.252868  0.512930 -0.298093  0.488518 -0.075572  1.131629   \n",
       "4 -0.222328 -0.200758  0.186561  0.410052  0.198300  0.119009 -0.670662   \n",
       "\n",
       "         X8        X9       X10  ...       X12       X13       X14       X15  \\\n",
       "0 -0.761207  0.319039 -0.249370  ... -2.060141 -0.322417 -0.384054  1.133769   \n",
       "1 -0.935769 -0.267888  0.530355  ... -0.396754 -0.687173 -0.845206 -0.671246   \n",
       "2  2.100255  0.120159  0.617203  ... -0.352250 -1.142518 -0.349343 -0.208894   \n",
       "3  1.519817  2.185575 -1.396496  ... -0.504466  0.160037  0.876169  0.315635   \n",
       "4  0.377564  0.121821  1.129484  ...  0.185156 -0.375285 -0.638730  0.423494   \n",
       "\n",
       "        X16       X17       X18       X19       X20  y  \n",
       "0 -1.099891 -0.172428 -0.877858  0.042214  0.582815  0  \n",
       "1 -0.012665 -1.117310  0.234416  1.659802  0.742044  1  \n",
       "2  0.586623  0.838983  0.931102  0.285587  0.885141  0  \n",
       "3 -2.022201 -0.306204  0.827975  0.230095  0.762011  0  \n",
       "4  0.077340 -0.343854  0.043597 -0.620001  0.698032  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gen_X\n",
    "df['y'] = gen_y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have constructed our simulated data set, 'df', that we use to demonstrate the modeling methods in the rest of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given a data frame containing both features and target (X's and y's), how to extract X and y in a simple fashion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y']\n",
    "X = df.drop(columns='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.624345</td>\n",
       "      <td>-0.611756</td>\n",
       "      <td>-0.528172</td>\n",
       "      <td>-1.072969</td>\n",
       "      <td>0.865408</td>\n",
       "      <td>-2.301539</td>\n",
       "      <td>1.744812</td>\n",
       "      <td>-0.761207</td>\n",
       "      <td>0.319039</td>\n",
       "      <td>-0.249370</td>\n",
       "      <td>1.462108</td>\n",
       "      <td>-2.060141</td>\n",
       "      <td>-0.322417</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>1.133769</td>\n",
       "      <td>-1.099891</td>\n",
       "      <td>-0.172428</td>\n",
       "      <td>-0.877858</td>\n",
       "      <td>0.042214</td>\n",
       "      <td>0.582815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100619</td>\n",
       "      <td>1.144724</td>\n",
       "      <td>0.901591</td>\n",
       "      <td>0.502494</td>\n",
       "      <td>0.900856</td>\n",
       "      <td>-0.683728</td>\n",
       "      <td>-0.122890</td>\n",
       "      <td>-0.935769</td>\n",
       "      <td>-0.267888</td>\n",
       "      <td>0.530355</td>\n",
       "      <td>-0.691661</td>\n",
       "      <td>-0.396754</td>\n",
       "      <td>-0.687173</td>\n",
       "      <td>-0.845206</td>\n",
       "      <td>-0.671246</td>\n",
       "      <td>-0.012665</td>\n",
       "      <td>-1.117310</td>\n",
       "      <td>0.234416</td>\n",
       "      <td>1.659802</td>\n",
       "      <td>0.742044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.191836</td>\n",
       "      <td>-0.887629</td>\n",
       "      <td>-0.747158</td>\n",
       "      <td>1.692455</td>\n",
       "      <td>0.050808</td>\n",
       "      <td>-0.636996</td>\n",
       "      <td>0.190915</td>\n",
       "      <td>2.100255</td>\n",
       "      <td>0.120159</td>\n",
       "      <td>0.617203</td>\n",
       "      <td>0.300170</td>\n",
       "      <td>-0.352250</td>\n",
       "      <td>-1.142518</td>\n",
       "      <td>-0.349343</td>\n",
       "      <td>-0.208894</td>\n",
       "      <td>0.586623</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.931102</td>\n",
       "      <td>0.285587</td>\n",
       "      <td>0.885141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.754398</td>\n",
       "      <td>1.252868</td>\n",
       "      <td>0.512930</td>\n",
       "      <td>-0.298093</td>\n",
       "      <td>0.488518</td>\n",
       "      <td>-0.075572</td>\n",
       "      <td>1.131629</td>\n",
       "      <td>1.519817</td>\n",
       "      <td>2.185575</td>\n",
       "      <td>-1.396496</td>\n",
       "      <td>-1.444114</td>\n",
       "      <td>-0.504466</td>\n",
       "      <td>0.160037</td>\n",
       "      <td>0.876169</td>\n",
       "      <td>0.315635</td>\n",
       "      <td>-2.022201</td>\n",
       "      <td>-0.306204</td>\n",
       "      <td>0.827975</td>\n",
       "      <td>0.230095</td>\n",
       "      <td>0.762011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.222328</td>\n",
       "      <td>-0.200758</td>\n",
       "      <td>0.186561</td>\n",
       "      <td>0.410052</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>0.119009</td>\n",
       "      <td>-0.670662</td>\n",
       "      <td>0.377564</td>\n",
       "      <td>0.121821</td>\n",
       "      <td>1.129484</td>\n",
       "      <td>1.198918</td>\n",
       "      <td>0.185156</td>\n",
       "      <td>-0.375285</td>\n",
       "      <td>-0.638730</td>\n",
       "      <td>0.423494</td>\n",
       "      <td>0.077340</td>\n",
       "      <td>-0.343854</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>-0.620001</td>\n",
       "      <td>0.698032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0  1.624345 -0.611756 -0.528172 -1.072969  0.865408 -2.301539  1.744812   \n",
       "1 -1.100619  1.144724  0.901591  0.502494  0.900856 -0.683728 -0.122890   \n",
       "2 -0.191836 -0.887629 -0.747158  1.692455  0.050808 -0.636996  0.190915   \n",
       "3 -0.754398  1.252868  0.512930 -0.298093  0.488518 -0.075572  1.131629   \n",
       "4 -0.222328 -0.200758  0.186561  0.410052  0.198300  0.119009 -0.670662   \n",
       "\n",
       "         X8        X9       X10       X11       X12       X13       X14  \\\n",
       "0 -0.761207  0.319039 -0.249370  1.462108 -2.060141 -0.322417 -0.384054   \n",
       "1 -0.935769 -0.267888  0.530355 -0.691661 -0.396754 -0.687173 -0.845206   \n",
       "2  2.100255  0.120159  0.617203  0.300170 -0.352250 -1.142518 -0.349343   \n",
       "3  1.519817  2.185575 -1.396496 -1.444114 -0.504466  0.160037  0.876169   \n",
       "4  0.377564  0.121821  1.129484  1.198918  0.185156 -0.375285 -0.638730   \n",
       "\n",
       "        X15       X16       X17       X18       X19       X20  \n",
       "0  1.133769 -1.099891 -0.172428 -0.877858  0.042214  0.582815  \n",
       "1 -0.671246 -0.012665 -1.117310  0.234416  1.659802  0.742044  \n",
       "2 -0.208894  0.586623  0.838983  0.931102  0.285587  0.885141  \n",
       "3  0.315635 -2.022201 -0.306204  0.827975  0.230095  0.762011  \n",
       "4  0.423494  0.077340 -0.343854  0.043597 -0.620001  0.698032  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "195    1\n",
       "196    0\n",
       "197    1\n",
       "198    1\n",
       "199    1\n",
       "Name: y, Length: 200, dtype: int32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Analytics: For each of the 20 features, which feature does the y=1 group have the higher average?\n",
    "#### Super slow way of doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.22157664e-01, -2.04966538e-01, -2.43240376e-01,\n",
       "        -3.63570421e-02, -1.93845863e-01,  9.36729581e-02,\n",
       "         2.62709812e-01,  2.13169647e-01,  2.00029658e-01,\n",
       "         4.63842261e-02,  7.77167483e-02, -6.72668629e-02,\n",
       "         4.06244529e-04,  9.16813708e-02,  9.95053160e-02,\n",
       "        -6.73780626e-02,  9.83761988e-02, -9.47603953e-02,\n",
       "        -6.94209204e-02,  4.91980066e-02],\n",
       "       [ 2.25164206e-01,  2.82792473e-01,  2.80512385e-01,\n",
       "         4.03376804e-01,  1.78792096e-01, -4.00832721e-01,\n",
       "        -1.61412650e-01, -1.31933518e-01, -8.48852940e-02,\n",
       "        -4.39996214e-01,  7.77267095e-02,  2.42083521e-01,\n",
       "         4.56481738e-02,  2.79365255e-02, -2.91626160e-01,\n",
       "         4.88051708e-02,  3.90577553e-02, -1.18110230e-02,\n",
       "         9.25214471e-02,  1.95490706e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_matrix = np.array((X[y==0].mean(), X[y==1].mean()))\n",
    "display(mean_matrix.shape, mean_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Less slow way of doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.222, -0.205, -0.243, -0.036, -0.194,  0.094,  0.263,  0.213,\n",
       "         0.2  ,  0.046,  0.078, -0.067,  0.   ,  0.092,  0.1  , -0.067,\n",
       "         0.098, -0.095, -0.069,  0.049],\n",
       "       [ 0.225,  0.283,  0.281,  0.403,  0.179, -0.401, -0.161, -0.132,\n",
       "        -0.085, -0.44 ,  0.078,  0.242,  0.046,  0.028, -0.292,  0.049,\n",
       "         0.039, -0.012,  0.093,  0.195]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(mean_matrix, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faster (more visually appealing) way of doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEXCAYAAACu1P9TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcVZn/8U8nBgyMENmEAFEQedgMIDsIxJFlEBxgQCOLgBACk0EFRWDYwR+IMprIsARBdgMKisiOQEAEAkRkh68OIluiKBAgbCbp/v1xTsNNWd11q5PqpOt+369XvVJ3OXVOVW4/de5zT53b0dXVhZmZtb9BC7oBZmbWPxzwzcwqwgHfzKwiHPDNzCrCAd/MrCIc8M3MKuIDC7oB1ryI6AIeA+YUVk+VNKaPr7cRcICkg+dH++q8/ihgMnCJpH1rtt0BbCjpX1pRdxn581xW0t/n4TW2Av4b+DjQCbwNfF/SZfOnlWbzzgF/4PrMvASoGmsDK82n1+rJdODzEbGYpLcAIuKjwOotrrflImIH4EfAHpJ+m9d9DLg5It6S9IsF2T6zbg74bSYi1gR+CCwNDAbOkHRBRAwCxgObAh8COoAxwHPAycCSEXEhcDFwpqR18uuN6l6OiBOBzYDhwMOS9o6IY4DdSOnBPwPjJE2r07RXgKeBXYBJed0++fl7ZxYRcQAwLr/ey8Ahkp6KiNWBs3LbVwAeAkZLeici3gFOA7bL274n6ZyIWB64BFgmv/z1ko7r4aM7JZ/pDAKOlXRdRPwa+Jmk83LbjgWWlnRYTdnvAYd1B3sASX+OiDHA4rnsRcBSpDOA64BT8/tZD+gCbgSOljS79oyjexlYB/gu8CywBuksYj9JT/bwnszm4hz+wDU5Ih4qPJaLiA8AVwFHSdoA2Bo4PCI2BTYhBerNJK1FCuxHSXoeOB64S9JXStT7UWD9HOz3AT4JbCxpPeAG4Pxeyl4CfLmwPJr3gz8RsTWwL7ClpPVJgfTqvPlA4GJJmwKrAasAO+ZtiwJ/l7Q5sDswPiI+mMv8SdKngC2BT0TEkj20rXu/vYGLI2JZUkA+MLdtEHAAMLFYKCKGkQLxzbUvKOkuSTcVVi0maW1JRwJnkL7QPglsCKwLHN5D24o2BP5X0kjgQuDSEmXMAPfwB7J/SulExFqkHuQFEdG9eigpQJ+Te6gHRcTHgVHAG32od4qk2fn5TsDGwNRc32BgsV7KXgucExEfIQXtp0g9/2475vX3FNr/4YhYCjgS2DYijiClgYYDxbz/NfnfB0lfAIsDNwE3RMQI4FbSF9xrPbRtIoCkxyLiCdKZzLXADyNi3VzfM5JUU64j//veHCUR8VMggEWAlySNypt+Wyi3A7CFpC7g3YiYCBxKOlPpzcOS7srPLwDOioilJb3coJyZe/htZjDwmqT1uh+kFM6FEbEjcH3e7xpSgOuo8xpdNesXqdk+s6a+7xbq2hDYoqfGSfoH8HPgS6Se/EV12n9p4fU+lV/zVeByYCwpnTGeFNiL7Xw719EdeDskPUA6E/gR8DHg/ojYoIfmFS+ADwJmSZoDnAvsnx8TawtJehV4kvQF2r1udG7/ON5PJ8Hcn90gCl8SeXlIYbkDICJqP//ZtfvUtN2sRw747UXA2xGxN0BErEwazbMBsC1wraRzgKmkXPrgXG427webvwEjcoqogxSce3IzMCYilsjLJ9M4xXAJsB+wFakHXvt6e0TECnn5YOC2/Hx74GRJP83LmxTaX1dEnAYcJ+mXwNeBx0npl3r2y2U+RTrLuC+vPx/YlfQZXl23JHwDOCMiNi/UvQTpDKinYHwzcEhEdETEoqQvs1/nbX8jfdEB7FlTbr2IGJmfjwXukTSjhzrM5uKA30ZyD3pnUhB+BLiFFPDuJvVOR0XEo6Te8dPAKjk3PQVYNSJ+IekJUq92al7/TC9Vnk+6ADklIh4HRpIDZy9tvJeUbrmukBrq3nYL6aLkr3P79wT+I/fajwauzu0/F7iTFJh7M4EUIB/L7+cZ4Ioe9l01In6f39OXJL2S2/RSLnu5pFk9vKebgD2AoyLikYh4CniAlDLdqYf6vgYsBzyaHwJOKWw7KyIeBNYkjXDq9hfSBeZHSV/axWsiZr3q8PTIZj2LiGVIwXurfIF7QbZlFIURVGbNcg/frAcRcSApP3/6gg72ZvODe/hmZhXhHr6ZWUU44JuZVYQDvplZRQyIX9o++OzrTV9oWGLokMY71ejL5YyVlx7afCHg/j+90ninGtvvP75PdY3ccZumywztw+e31IcWbboMwI1nXth0mTMmfqtPdW264tJNl7np/15qusw7szubLgMw4dIHmi5z9P6bNF1m1py+Xbub9nrdkam92mClxftUVwz7UJ/KbbrasHo/KCztndmU/nA++IG6P15caA2IgG9m1l/aeRyLA76ZWUFX+Q4+9WcnWXg54JuZFbmHb2ZWDW0c7x3wzcyKOptK4julY2Y2cLVxF98B38ysoI3jvQO+mVmRh2WamVVEc8MyBxYHfDOzAvfwzcwqwgHfzKwinNIxM6sI9/DNzCqijeO9A76Z2VzaOOI74JuZFTQ3tcLA4oBvZlbQvuHeAd/MbG5tHPEd8M3MCjws08ysIto4he+Ab2ZW1Mbx3gHfzKyoq427+A74ZmYFrYr3EbEncCwwBJgg6aya7bsCJwGDgQeAsZL+EREjgMuA5QABe0ma2Zc2DJqH9puZtZ2uJh5lRcSKwCnAp4H1gLERsVZh++LAmcC2ktYGPgjslzefDZwtaQ1gKnBcX9+bA76ZWUFXV/lHE7YBbpf0iqQ3gauA3bs35nUfk/TXiFiM1Jt/NSKGAFvl/QEuAr7Q1/fmlI6ZWUEzwzIjYhgwrM6mGZJmFJaHA9MLy9OBjYsFJM2KiB1I6ZsXgVuAZYDXJc0ulFupdANruIdvZlbUXE7nUOCZOo9Da151EHNngTqAztqqJd0oaWngOuCcOuWoV64sB3wzs4LOrvIPYAKwSp3HhJqXfQFYobC8PDCteyEiloqI7QrbfwKMBF4CloyIwXn9CsVyzXJKx8ysoJmUTk7bzGi4I9wKnBgRywJvArsBYwvbO4DLImJDSc+R8vS/zWmeu4DRwCRgH+DG0g2s4R6+mVlRC4bpSHoROAaYDDwETJJ0f0TckIP8y6QvgOsi4mEggCNz8XGkUT1PAFuShnb2iXv4ZmYFrfrZlaRJpF56cd3nCs9/CfyyTrlngVHzow0O+GZmBW38Q1sHfDOzIk+tYGZWEe0b7h3wzczm0sYdfAd8M7Mi3wDFzKwq2jfeO+CbmRW1cbx3wDczK+ps4yS+A76ZWVH7xnsHfDOzojaO9w74ZmZFbZzRccA3MyvysEwzs6po33jvgG9mVtTpgG9mVg1O6ZiZVUX7xnsHfDOzojaO9w74ZmZFHpZpZlYRvgGKmVlFtG+4d8A3M5tLG3fwHfDNzIo8LLNJETGit+2SnmtFvWZm86x9433LevjXA58ApgEdNdu6gFVbVK+Z2Txp43jfsoC/BXAXME7S3S2qw8xsvpvTxkn8Qa14UUmvAwcC+7bi9c3MWqWrq/xjoGnZRVtJ9wP3t+r1zcxawRdtzcwqwrNlmplVhHv4ZmYVMRBz82U54JuZFbRqlE5E7AkcCwwBJkg6q4f9LgFul3RRXt4XOA34a97leknH9KUNDvhmZgWtSOlExIrAKcAGwLvAPRExWdIThX2GA+cCnwVuLxTfEPiGpMvntR0O+GZmBc108CNiGDCszqYZkmYUlrch9dpfyeWuAnYHTi7ssxdwDfByzWttBHwiIo4GHga+KunV8q18X0vG4ZuZDVRNjsM/FHimzuPQmpcdDkwvLE8HViruIOl0SefXadJ04NvASOB54My+vjf38M3MCjqbS+lMAC6qs35GzfIg5p61oQPoLFOBpF27n0fE94Cnm2lgkQO+mVlBZxM5nZy2qQ3u9bwAbFlYXp4011ivImJJYH9J4/OqDmB26QbWcErHzKygRVMr3Ap8NiKWjYjFgN2Am0qUmwkcERGb5OVDgKubqrnAAd/MrKCTrtKPsiS9CBwDTAYeAiZJuj8iboiIDXspNwf4InBORDxJGuVzRF/fm1M6ZmYFrfrhlaRJwKSadZ+rs99+Nct3AZ+aH21wwDczK2jjH9o64JuZFXW18dwKDvhmZgXtfAMUB3wzs4L2DfcO+GZmc3FKx8ysIkr9/HWAcsA3MytwD9/MrCLaON474JuZFXmUjplZRbRvuHfANzObi3P4ZmYV4VE6ZmYV0cYdfAd8M7OiOZ3tG/Ed8M3MCpq549VA44BvZlbQxh18B3wzs6I27uA74JuZFTVz68KBxgHfzKzAPXwzs4qY3cZJfAd8M7MC9/DNzCqijTv4DvhmZkWeS8fMrCIq38OPiH8Bjge2B+YA1wKnSnq3hW0zM+t3ng8fzicF+sOAQcCBwBnAQS1ql5nZAlH5Hj6wvqToXoiI24HHW9MkM7MFp407+Awqud/0iFimsLw48PcWtMfMbIHq7Ooq/Rhoyvbwnwd+FxFXArOBnYG/RsQZAJK+1qL2mZn1K6d04P/yo9sVLWiLmdkC16qOe0TsCRwLDAEmSDqrZvt6pOulSwC/AQ6WNDsiRgCXAcsBAvaSNLMvbSgV8CWd1JcXNzMbaFpxA5SIWBE4BdgAeBe4JyImS3qisNtlwBhJUyLix6TBMecAZwNnS7oiIo4DjgOO7Es7yg7LfJQ6N3OXNLIvlZqZLaxadE/bbYDbJb0CEBFXAbsDJ+fljwJDJU3J+18EnBQR5wNbAbsU1t9JKwM+cEjh+SLAl4A/9aVCM7OFWTMXYyNiGDCszqYZkmYUlocD0wvL04GNG2xfCVgGeF3S7Jr1fVI2pXNncTkibgXuIZ2imJm1jSZz+IcCJ9RZfxJwYmF5EHNnSTqY+2Sip+2162EeTkL6OrXC0qRvJDOzttJkCn8CKc1Sa0bN8gvAloXl5YFpNdtXqLP9JWDJiBgsaU7ep1iuKX3J4XcAI4Bz+1qpmdnCqpnJ03Lapja413MrcGJELAu8CewGjC28zrMR8U5EbCHpbuDLwI2SZkXEXcBoYBKwD3Bj6QbW6EsOvwv4m6Qn+1qpmdnCanYLrtpKejEijgEmk66Dni/p/oi4AThe0lRgL+C8iFgCeJA0fQ3AOODiiDgWeA7Yo6/tKJ3Dj4hNgH8jjSG9BXDAN7O206rpkSVNIvXSi+s+V3j+MHNfyO1e/ywwan60oaPMm4uILwOnAj8nXUTYDThR0nnzoxGNrHb4jU3/DyyyyOCm65n5xjtNl9l+y1WbLgMw5dHpjXeqcfjOa/Spro1XXKrpMm++M6fpMn0dv/yb519uusywoc3//wLcrlebLrPSUkObLrPO8os1XQZgcEdH02Wuf7z5WU52XHuZxjvV8bPfNX/cLrZo3y4VbvSxJftU7ptbr9r8h1jwX1c/WfpAPmvXNeeprv5W9n/iG8DGkqYDRMRppF5+vwR8M7P+0s43QCk7edqg7mAPIGkaabpkM7O20tVV/jHQlA34L0fEzt0LEbEL0Py5sZnZQm5OZ1fpx0DTzCidX0XEmaRROrN4/6e+ZmZto51TOmUD/ieAAFYHBgNPFX7qa2bWNto43pcO+KdKugYPxTSzNjcQb2xSVtmA/2j+0cBdwHvzMEt6sCWtMjNbQNo33JcP+JvkxwE16/s2CN3MbCHVzjn8hqN0ImIlYAdJqwCXA9cD1wBrt7htZmb9rp1H6fQa8CNiY9KcDhvkVV8k3bx8beA/W9s0M7P+V+Vx+N8GRkv6SV5+I9/u8EDmYQIfM7OFVVdXV+nHQNMo4K8qaXJhuQPem8yn+QlazMwWcp1d5R8DTaOLtu/WLBcn8C8zB7SZ2YAyEHvuZTXq4c/MF20BkDQTICJWBt5qZcPMzBaEriYeA02jgP8jYFJELNe9IiI+DFwInN3KhpmZLQjtPEqn15SOpAsiYjXgmYh4gvSltgbwQ0mX90cDzcz6UzundBr+8ErS0RExAdiMdNH2vuJUyWZm7aSN433pWxy+RPqxlZlZW/NcOmZmFdHG8d4B38ysaCBejC3LAd/MrKBrQA64LMcB38yswCkdM7OKqPSwTDOzKmnjFL4DvplZkXv4ZmYV4VE6ZmYV0cYdfAd8M7Mip3TMzCqijeO9A76ZWVF/9vAjYgRwGbAcIGCv7vuO1Nl3W+AoSZ/Ny0OAl4E/FXbbQNKcnupzwDczK+jnHv7ZwNmSroiI44DjgCOLO0TEIOAw4Gjg0cKmkcC9krYvW1mjG6CYmVVKZ2dn6ce8yD30rYCr8qqLgC/U2XXN/DiwZv1GwLIRMTUipkTE1o3qdA/fzKygmR5+RAwDhtXZNENSo/t+LwO8Lml2Xp4OrFS7k6THgTERMaq2qcAvge8A6wA3RsQ6kv7eU4UO+GZmBU3m8A8FTqiz/iTgxO6FiPgCML5mnz/yz7fGLX3aIOncwuLvI+I+YAt6uXeJA76ZWUGTOfwJpFRMrbl695KuBK4sruu+6BoRg/OF1hWAaWUrjogvA/dIejqv6gBm9VbGAd/MrKCZHn5O2zRK3fRUdlZE3AWMBiYB+wA3NvES65JuPTsuIgJYH7irtwIO+GZmBZ39O7XCOODiiDgWeA7YAyAiDgaGSzq+l7InAxdExGOk1NA+kt7orTIHfDOzgv4clinpWWBUnfUT66y7o7ivpNeB3ZupzwHfzKzAUyuYmVVEG8d7B3wzsyL38M3MKqKN470DvplZUT+P0ulXDvhmZgVO6ZiZVYQDvplZRbRxvHfANzMrcg/fzKwi5sxxwDczq4Q27uA74JuZFTml0wcRsQZpYp+VSJP6TwNukjS1VXWamc2rNo73rbmnbUSMA67Iiw8AD+bn50XEN1tRp5nZ/NDV1VX6MdC0qof/dWB9SW8VV0bED0jB//stqtfMbJ4MwDheWqsC/mxgSJ31Q2lwCy4zswWps7P0bWUHnFYF/FNIN9W9jXQn9i5gOPCvwDEtqtPMbN61cQ+/JTl8SZOAT5Pur/gW8G5+vqWkK3ora2a2IDmH3weSpgGXtOr1zcxaYSAG8rI8Dt/MrMAB38ysIhzwzcwqoss3QDEzqwb38M3MKsIB38ysKto33jvgm5kVuYdvZlYRnlrBzKwi3MM3M6uK9o33DvhmZkXu4ZuZVUR/BvyIGAFcBiwHCNhL0syafVYALgWWBd4BDpL0UER0AKcDO5HuKnigpLt7q68ls2WamQ1U/Txb5tnA2ZLWAKYCx9XZ51TgKknrAifkMgC7AWsCawG7ABdFRK+dePfwzcwKmplaISKGAcPqbJohaUaDskOArUjBGuAi4E7gyJpdDyg8XwV4NT/fEbhCUifwh4h4Dtgc+E1PdTrgm5kVNNlzP5TU6651EnBig7LLAK9Lmp2XpwMr1e6UAzoR8RTwMWDnvGl4LtOtbvkiB3wzs4ImA/4EUs+81ly9+4j4AjC+Zp8/8s9jgnr8EYCkNSJiPeCWiFiDlJIvlu/orTw44JuZzaWZgJ/TNr2mbvJ+VwJXFtfllM7LETFY0hxgBWBabdmI2BG4U9LMfLH2WWBV4IVcptvy9coX+aKtmVlRVxOPeSBpFunWr6Pzqn2AG+vsui8wFiAi1iIF9qeAG4C9ImJwRKwGrA480FudDvhmZgX9PEpnHDA2Ip4AtgSOBYiIgyPi5LzPocD2EfEwcCGwRx66eRXwOPAIcA1wgKS3e6vMKR0zs4L+nEtH0rPAqDrrJxaeTwO2r7NPF3B4fpTigG9mVuBf2pqZVUX7xnsHfDOzIvfwzcwqwgHfzKwqOucs6Ba0jAO+mVmRe/hmZhXR5VscmplVg3v4ZmYV4R6+mVlFOOCbmVWER+mYmVWEc/hmZhXhlI6ZWUW4h29mVhHu4ZuZVYR7+GZmFeFROmZmFeGUjplZRXQ6pWNmVg3u4ZuZVYQDvplZRfiirZlZRXhYpplZRTilY2ZWEe7hm5lVhHv4ZmYV4R6+mVlFeJSOmVlFOKVjZlYRbZzS6ehq4zdnZmbvG7SgG2BmZv3DAd/MrCIc8M3MKsIB38ysIhzwzcwqwgHfzKwiHPDNzCrCAd/MrCIc8M3MKmLATq0QEXsCxwJDgAmSzipZbgngHmAnSX8usf8JwBfz4vWSjihZz8nA7kAX8GNJPyhTLpf9H2AZSfuV3H8ysBwwK686SNJ9Dcp8HjgBWBy4RdLXS9QzBjiksGoV4FJJh/RQpLvc3sB/58UbJR1eoq6jgK8A7wI/lXRKL/vO9X8aEdsAPwCG5rLHlimX1w0BbgK+LemOEnWNBb5G+n+eSvrs/1Gi3H+SPssO4HrgCEldvZUprD8E2F3SqBL1XAh8Gngz73KSpKtLlNsMGA98CHgE2Lf2fRXLAGsBpxY2rwjcJ2mnBvVsB5wODAYeBMaU/Pz2A44A5gC3A9+UNLu2nM1tQPbwI2JF4BTSgbweMDYi1ipRbhPgt8DqJevZBtgOWD/Xs0FE7Fqi3NbAvwIjgQ2Br0ZElKzzs8C+ZfbN+3eQ3s+6ktbLj0bBflVgIrBLbuOnImKHRnVJOr+7DmAv4CXgxAZ1LQacAWwNrAtsmT/X3spsA+wJbET67DeJiP/oYd+5/k8jYihwAbAzsCawUb33Vu9YyP9HdwCbl6xrdeBbef+RpL+n/ypRbhXgG8DGwCdz+W0btS+vXws4qkz7sg2BrQrHRr1gX9u+JYBfAGMlrZ13O6C3MpJuKBwb/wa8DhxWon0/Br4kaR1gMWCfEu0L4P8Bn5X0SVKn72v1PhOb24AM+MA2wO2SXpH0JnAVqTfdyIGkP8hpJeuZTuo5/EPSLOBJYESjQpLuBD6TexzLkc6k3uy9FETEUqQvslMb7Vsslv+9JSIezr2/RnYl9XxfyO9rNNDrl0Qd5wBHS/p7g/0Gk46zxUl/mEOAtxuUWR+4WdLrkuaQety79LBv7f/pxsAfJT2TP//LgC+UKAcpqJ1Oz59FbZl3gXG5nV3Ao9Q/PuYqJ+kZYK187A4DlgRmNGpfRCwKnAscX6Z9+ct2BHBBRDwSESdFRL2/+dq6tgXulfRIXv4qUPtF0dvf0unAREl/LFFmMLBERAwGPkj9Y6O23Mjcvul5+Tp6Pj6sYKCmdIaTgnG36aQ/9F5JGgNQsrONpMe7n0fEJ0ipnS1Klp0VEScBhwNXAi+WKHYucAywcqkGJh8GbiP9UQ4B7ogISfp1L2VWA/4REb8iBYTrgOPKVph74EMlXdloX0lvRMRxwFPAW8CdpFPz3jwIjI+I7+Qy/04PnZM6/6f1jo2VSpSjO10XEYeWqUvSs8Czed2ypBTNfiXrmhURBwL/A9wPPNSoDPAd0tnLM2XaByxPSneMA14j/T8fAJzXoNxqwMyIuAJYA7gb+GaJ9nX/nYwCxpRoH7ltd5DOCJ4hdd4alXsY+EFErEz6Etg9v1drYKD28AeRcqbdOoCWTWIdEWsDvwa+VafX0iNJJwDLkgL4gQ3qGAM8L+m2Ztom6V5J+0h6Lfe2fwx8rkGxD5DOkg4ANgM2oYk0EnAQKUfeUESMBPYHPkoKxnNIX4I9yp/BRaRAcBPpdP6f8ro96NdjA95LMd5GulZzR9lyks4Dlgb+QuPU2LbACEkXNvH6f5K0q6Tpkt4C/pfGxwak42N70nWXDUhnZ3XTSHWMBc6W9G6jHSNieeA0YB1gBWAKJY4rSX/I7fkVcBfpGkPZ46PSBmrAf4F0gHRbnvJpmqZExBakP+ajJF1csswaEbEeQP5D+wXpNLQ3o4HtIuIh4GTg3yNifIm6Pp3z/t06eP/ibU/+Atwq6W+S3iadrjc8Q8r1LULKx/+qzP6kwHGbpJdyELiI1APsrY4PAT+XNDJfmHwXeLpkff12bED6vyadsVws6dsly6ycjyty2ukKGh8fewBr5+PjfGDDiPhpg3o+GRG7FVaVOTYgHR9TclpsDvAzSh4fpNTKFSX33RJ4TNLTkjpJZx6jGhWKiA8C90taX9LmpLPnssdHpQ3UlM6twIn5NPpNYDdSz2K+yqeMvwRGS7q9iaKrAidFxKdJvc2dSafiPZL03kW7PAJhlKTDei7xnmHAyRGxOSmlsy9wcIMy1wEXR8Qw4A1gB9L7LGMk8Iecfy7jYeB7EbE4KT3zeeCBBmVWAS6JiA1JvcsDqLlo2Iv7SNf1ViOlCPakwWffV/mL6RbgGEmXNlF0SeAnuVPwGikl8dveCkjav1DvKOBESaMb1NMBTIiI24GZpL+RMp2WW0jH78qSnieNwvldo0IRsQwp1Vc35VTHY8D3I+Ijkv5K+jtpdGxAOiZuy2fe75LSmRNL1llpA7KHL+lFUq57Min3OUnS/S2o6nDShaQfRMRD+dEomCLpBtJQu9+T/lDukVS219MUSdfV1HWBpHsblLkP+B4pyDxBykOXTRWsSupFl23fLcDluW2PkL6UTmtQ5hHg53n/+0nDbu8uWd87pDz6z0nv7Snq5IXnkzHAR4BvFo6Pk0u08TFSPv4e0hfiW8D353fj8uf4HVIO/gngIUmXlyj3PCltd21EPAUslV+nkWaPjSdJ144mR8QjpBFFDYfsSnoZOImUAnqMNIBjUtl6q8x3vDIzq4gB2cM3M7PmOeCbmVWEA76ZWUU44JuZVYQDvplZRQzUcfg2AEVEF2kY3ZzC6qndP53vw+ttBBwgqeFQWTNzwLf+95kSE66VtTZ15skxs/oc8G2hEBFrAj8kzS0zGDhD0gV5dsfxwKakudk7SD94eo40BcWSkeZ8vxg4M0+z2/1r1DMlrRMRJ5LmDBoOPCxp74g4hvQL7UHAn0mzXrZsCgazhYEDvvW3yRFRTOlsB7xC+jXslyU9GBFLAvdGxBOkAD8c2ExSZ6Qboxwl6fMRcTzpRiBfyQG+Nx8F1pE0OyL2Ic1Dv3FeHkuan6bMxGJmA5YDvvW3f0rp5Jt6fJw0b3v36qHA+pLOiYhjgYMi4uOkybXe6EO9U/T+HZF2Ik0GNjXXN5h08w2ztuaAbwuDwcBr+W5JAETER4DXImJHUqrn+8A1pLlx9q7zGl2ks4Fui9Rsn1lT33clnZPrWpR0XwGztuZhmbYwEPB2pHvfdlLtehgAAAC2SURBVM9S+hhpLvZtgWtzcJ5Kmn53cC43mzQZG8DfgBERsVyk2z5+qZf6bgbG5Fv5QboW0Mxsl2YDkgO+LXBKN63emRSEHyFNz3tcniFzIjAqIh4l3QnraWCVfDF3CrBqRPxC0hOkO4ZNzet7m6L3fNIU0VMi4nHSlM/7teTNmS1EPFummVlFuIdvZlYRDvhmZhXhgG9mVhEO+GZmFeGAb2ZWEQ74ZmYV4YBvZlYRDvhmZhXx/wHbM8xd4efgvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sns.heatmap(mean_matrix, annot=False, linewidths=0, \n",
    "            square = False, cmap = 'Blues_r');\n",
    "fig.set_ylim([0,2]);\n",
    "plt.ylabel('Group');\n",
    "plt.xlabel('Feature');\n",
    "all_sample_title = 'Feature Means by Group'\n",
    "plt.title(all_sample_title, size = 12);\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "We can see that the two groups differ in their patterns of mean feature values. This is a reflection of how the different features contribute to the logit model through the coefficient vector weighting of features to generate 0/1 responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 6: Non-regularized Regression Models</h1>  \n",
    "\n",
    "### Two Main Purposes of Non-Regularized Regression Models\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### For Non-Regularized Linear or Logistic Regression, when should I use statmodels package vs. scikit-learn package?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "In previous sections we used the Statmodels formula API to fit linear and logistic regression models. The advantage of the statsmodels API is in the amount of information it provides about model parameters, standard errors and hypothesis testing. Statsmodels is the current preferred choice if our goal is to make inferences about the model parameters. \n",
    "\n",
    "As an alternative, Scikit-Learn provides machine learning tools focused on predictive analysis. The characteristics:\n",
    "\n",
    "* Integration with machine learning tools for **cross-validation**;\n",
    "\n",
    "\n",
    "* Routine implementation of **regularization** for modeling with high-dimensional feature matrices;\n",
    "\n",
    "\n",
    "* Several choices for numerical optimizers for solving regularized regression problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 7: (RECAP) How do we implement a penalty for the number of featues in a non-regularized regression model? </h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Regularization penalties automate feature selection to some extent, as an alternative to tracking AIC or BIC. \n",
    "\n",
    "### First, let's review what we do with non-regularized logisic regression.\n",
    "\n",
    "### <u> Non-Regularized Logistic Regression</u>: Objective Function \n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "First consider \"ordinary\" **maximum likelihood estimation** for the logistic regression. We solve numerically for the coefficient estimates using a numerical optimization method such as a quasi-newton algorithm. The solver maximizes the log-likelihood, equivalently, minimizes twice the negative log likelihood:\n",
    "\n",
    "#### 1. What we do when fitting a SINGLE logistic regression model:\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Likelihood fit} & = -2* {llf} = -2*LLF(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p) \\\\ \\\\\n",
    "&= -2 \\sum_{i=1}^n \\{ y_i \\log(\\hat{p}_i) + (1-y_i) \\log(1-\\hat{p}_i)\\}\\\\ \\\\\n",
    "& \\ge 0.\\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. After fitting MANY non-reguliarzed logistic regression models (with different combinations of explanatory variables), how do we select which model is best?\n",
    "\n",
    "Using the *Optimal* Objective Function *Values* of SEVERAL Non-Reguliarzed Logistic Regression Models we MANUALLY Select the a Model that is Parsimonious\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "If we compare models with different numbers of coefficients using BIC, for example, we are attempting to minimize an overall criterion of the form:\n",
    "\n",
    "$$\n",
    "-2 * llf + p*\\log(n) = \\text{likelihood fit} + \\text{complexity penalty}\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 8: Automating Model Selection </h1>  \n",
    "\n",
    "## IDEA: *How* can we automate this process so we don't have to fit multiple models? Aka: how can we make it so we only have to find the optimal solution to just ONE objective function?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## IDEA: *Why* would we want to automate this process so we don't have to fit multiple models? \n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 9: How can we modify the logistic regression objective function such that models having lots of features are penalized? </h1>  \n",
    "\n",
    "## Three common methods of introducing penalties into the objective function\n",
    "\n",
    "**Regularization penalties** combine the likelihood criterion and the penalty into one optimization criterion for estimating the feature coefficients. For a given level of complexity this can produce fitted models with better mean-square error predictive properties. Here a few choices that are currently in common use:\n",
    "\n",
    "### <u>Method 1</u>: L2 penalty (Ridge regression)\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Minimize: } (-2*llf) + \\lambda \\sum_{j=1}^p \\hat{\\beta}_j^2\n",
    "$$\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Shrinks parameters toward smaller absolute values to reduce variance. In linear regression this is called ridge regression. $\\lambda$ controls tradeoff between fit and shrinkage. It reduces the effect of correlation between features, which is an issue in high dimensions.\n",
    "\n",
    "#### Using the ridge regression objective function, what types of optimal solutions for $\\hat{\\beta}_0, \\hat{\\beta}_1, ...,\\hat{\\beta}_p$ will minimize this function the most?\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### What would it mean if the optimal solution ($\\hat{\\beta}_0, \\hat{\\beta}_1, ...,\\hat{\\beta}_p$) of  the ridge regression objective function was one in which $\\hat{\\beta}_1=0, \\hat{\\beta}_2=0 ...,\\hat{\\beta}_p=0$?\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Method 2</u>: L1 penalty (LASSO)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Minimize: } (-2*llf) + \\lambda \\sum_{j=1}^p \\vert \\hat{\\beta}_j \\vert\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### Using the ridge regression objective function, what types of optimal solutions for $\\hat{\\beta}_0, \\hat{\\beta}_1, ...,\\hat{\\beta}_p$ will minimize this function the most?\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### Which objective function will penalize \"small\" values of $\\beta_i$ more: LASSO objective function or ridge regression objective function?\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### Why would you want to use LASSO over ridge regression?\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "Produces sparse solutions (small number of nonzero parameters) by zeroing out some parameters. $\\lambda$ controls tradeoff between fit and sparsity. This method directly reduces redundant features. \n",
    "\n",
    "\n",
    "#### Why would you want to use ridge regression over LASSO?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### In LASSO and Ridge Regression, you select the value of $\\lambda$ *before* fitting the model. Selecting different values of $\\lambda$ may produce different optimal solutions. What types of solutions will LARGE values of $\\lambda$ prioritize for LASSo and Ridge Regression?\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Method 3</u>: Elastic Net Regression (Combination of LASSO and Ridge Regression)\n",
    "Combines L1 and L2 penalization to produce sparse, low variance solutions. $\\lambda$ controls the tradeoff between fit and penalization. $\\alpha \\in [0,1]$ controls the relative weight of L1 versus L2 penalization.\n",
    "\n",
    "$$\n",
    "\\text{Minimize: } (-2*llf) + \\lambda \\left(\\alpha \\sum_{j=1}^p \\vert \\hat{\\beta}_j \\vert \n",
    "+ {1-\\alpha \\over 2} \\sum_{j=1}^p \\hat{\\beta}_j^2 \\right)\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### What types of solutions will LARGE values of $\\lambda$ prioritize for Elastic Net Regression?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### What types of solutions will LARGE values of $\\alpha$ prioritize for Elastic Net Regression?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "#### What types of solutions will SMALL values of $\\alpha$ prioritize for Elastic Net Regression?\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current default setting in the Scikit-Learn LogisticRegression module is L1 regularization. The function sets the degree of penalization using the input C, which is inversely related to $\\lambda$. The default setting is C=1. Smaller values of C correspond to heavier regularization or more sparsity in the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 10: Simulation Example Continued: Compare Different Penalties </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our simulated data with 20 features, let's compare for 4 different options for regularization.\n",
    "1. Basic Logistic Regression (ie. no penalty)\n",
    "2. Logistic Regression with L1 penalty (ie. LASSO Logistic Regression)\n",
    "3. Logistic Regression with L2 penalty (ie. Ridge Logistic Regression)\n",
    "4. Elastic Net Logistic Regression (Combination of L1 and L2 penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the Regularization Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the $\\lambda$ value.\n",
    "\n",
    "In sklearn, $C=\\frac{1}{\\lambda}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=0.3  # set the amount of penalization (1/lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running each of the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Logistic Regression (no penalties)\n",
    "* Using the 'newton-cg' solver. The newton-cg algorithm is a type of numerical analysis algorithm that goes about finding an optimal solution to a given objective function.\n",
    "* This algorithm stops after 1000 iterations or when the algorithm has converged.\n",
    "* The 'newton-cg' solver only works for: basic logistic regression and ridge regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='none',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf0 = LogisticRegression('none', solver='newton-cg', \n",
    "                          max_iter=1000)\n",
    "clf0.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Logistic Regression (L1 penalties)\n",
    "* Using the 'liblinear' solver. liblinear is a tool that solves linear logistic regression optimization problems.\n",
    "* This algorithm stops after 1000 iterations or when the algorithm has converged.\n",
    "* The 'liblinear' solver only works for: LASSO logistic regression and logistic ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = LogisticRegression('l1', solver='liblinear', \n",
    "                          max_iter=1000, C=C)\n",
    "clf1.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Ridge Regression (L2 penalties)\n",
    "* Using the 'liblinear' solver. liblinear is a tool that solves linear logistic regression optimization problems.\n",
    "* This algorithm stops after 1000 iterations or when the algorithm has converged.\n",
    "* The 'liblinear' solver only works for: LASSO logistic regression and logistic ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression('l2', solver='liblinear', \n",
    "                          max_iter=1000, C=C)\n",
    "clf2.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Logistic Regression (Combination of L1 and L2 penalties)\n",
    "* Using the 'saga' solver. saga is a numerical optimization method that only works for specific types of objective functions.\n",
    "* This algorithm stops after 1000 iterations or when the algorithm has converged.\n",
    "* The 'saga' solver only works for: elastic net logistic regression.\n",
    "* The $\\alpha$ in sklearn is represented as the \"l1_ratio\" parameter in the function. With an $\\alpha=$l1_ratio=0.7, this means that this particular elastic net model will favor solutions that more closely resemble:\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=0.7, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='elasticnet',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = LogisticRegression('elasticnet', solver='saga', \n",
    "                          max_iter=1000, l1_ratio=0.7, C=C)\n",
    "clf3.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(clf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's extract the 20 resulting slope coefficients for each of the 4 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91339789,  0.84105838,  0.83298926,  0.65831549,  0.50126758,\n",
       "        -0.87714052, -0.739675  , -0.73085726, -0.53128786, -0.97850072,\n",
       "         0.        ,  0.17358884,  0.01481474, -0.13674186, -0.29364757,\n",
       "         0.        ,  0.        ,  0.        ,  0.03755442,  0.06074195]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.94797261])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.448386</td>\n",
       "      <td>0.862878</td>\n",
       "      <td>0.943341</td>\n",
       "      <td>0.913398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.099151</td>\n",
       "      <td>0.794844</td>\n",
       "      <td>0.852618</td>\n",
       "      <td>0.841058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.911414</td>\n",
       "      <td>0.789636</td>\n",
       "      <td>0.869266</td>\n",
       "      <td>0.832989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.763950</td>\n",
       "      <td>0.590481</td>\n",
       "      <td>0.706093</td>\n",
       "      <td>0.658315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.011388</td>\n",
       "      <td>0.462536</td>\n",
       "      <td>0.549192</td>\n",
       "      <td>0.501268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-2.277685</td>\n",
       "      <td>-0.818814</td>\n",
       "      <td>-0.893153</td>\n",
       "      <td>-0.877141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-1.817789</td>\n",
       "      <td>-0.713729</td>\n",
       "      <td>-0.773147</td>\n",
       "      <td>-0.739675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-1.840509</td>\n",
       "      <td>-0.684439</td>\n",
       "      <td>-0.776345</td>\n",
       "      <td>-0.730857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-1.400668</td>\n",
       "      <td>-0.493109</td>\n",
       "      <td>-0.588224</td>\n",
       "      <td>-0.531288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-2.610932</td>\n",
       "      <td>-0.890087</td>\n",
       "      <td>-1.001949</td>\n",
       "      <td>-0.978501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.141495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.543221</td>\n",
       "      <td>0.121319</td>\n",
       "      <td>0.255975</td>\n",
       "      <td>0.173589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.213494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090158</td>\n",
       "      <td>0.014815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>-0.661488</td>\n",
       "      <td>-0.090676</td>\n",
       "      <td>-0.236996</td>\n",
       "      <td>-0.136742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>-0.741134</td>\n",
       "      <td>-0.235318</td>\n",
       "      <td>-0.333969</td>\n",
       "      <td>-0.293648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>-0.097251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>-0.165984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.042778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.204026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042845</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.222341</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.120741</td>\n",
       "      <td>0.037554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.344166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131761</td>\n",
       "      <td>0.060742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3\n",
       "0   2.448386  0.862878  0.943341  0.913398\n",
       "1   2.099151  0.794844  0.852618  0.841058\n",
       "2   1.911414  0.789636  0.869266  0.832989\n",
       "3   1.763950  0.590481  0.706093  0.658315\n",
       "4   1.011388  0.462536  0.549192  0.501268\n",
       "5  -2.277685 -0.818814 -0.893153 -0.877141\n",
       "6  -1.817789 -0.713729 -0.773147 -0.739675\n",
       "7  -1.840509 -0.684439 -0.776345 -0.730857\n",
       "8  -1.400668 -0.493109 -0.588224 -0.531288\n",
       "9  -2.610932 -0.890087 -1.001949 -0.978501\n",
       "10  0.141495  0.000000  0.003993  0.000000\n",
       "11  0.543221  0.121319  0.255975  0.173589\n",
       "12  0.213494  0.000000  0.090158  0.014815\n",
       "13 -0.661488 -0.090676 -0.236996 -0.136742\n",
       "14 -0.741134 -0.235318 -0.333969 -0.293648\n",
       "15 -0.097251  0.000000  0.047848  0.000000\n",
       "16 -0.165984  0.000000 -0.042778  0.000000\n",
       "17  0.204026  0.000000  0.042845  0.000000\n",
       "18  0.222341  0.003096  0.120741  0.037554\n",
       "19  0.344166  0.000000  0.131761  0.060742"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcoef = pd.DataFrame(\n",
    "    np.concatenate((clf0.coef_.T, \n",
    "                    clf1.coef_.T, \n",
    "                    clf2.coef_.T, \n",
    "                    clf3.coef_.T), \n",
    "                   axis=1)\n",
    ")\n",
    "dfcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize the slope differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dfcoef.index, bvec, lw=3)\n",
    "for i in range(4):\n",
    "    plt.plot(dfcoef.index, dfcoef[i])\n",
    "plt.xticks(np.arange(0,20,1))\n",
    "plt.xlabel('Coefficient index')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Coefficient Estimates Using Several Penalties')\n",
    "plt.legend(['True', 'None','L1','L2','EN'], loc='upper right')\n",
    "plt.hlines(y=0, xmin=0, xmax=19, linestyles='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the slope differences that we observed corroborate how we *expect* the different models to behave?\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# demo the for loop\n",
    "for i in range(4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the unregularized ML coefficients have the most variation, and appear to stray farther from the true population values than the regularized estimators. The penalized estimators are biased toward zero, which reduces variation amd also appears to improve their accruacy. Where the coefficients are close to zero, L1 and ElasticNet zero them out.\n",
    "\n",
    "Note: C=1 is the default setting for the amount of penalization. Smaller values of C increase the amount of penalization. Here we used C=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Topic 11: Regularized Logistic Regression with Train/Test split in Sci-Kit Learn</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate using the simulated binary response data. We'll generate the feature matrix $X$ and a binary target array $y$ from a logistic regression model with 20 features.\n",
    "\n",
    "## First, let's train the a LASSO logistic regression model using a *single* training dataset and a *single* test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import the model class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create an instance of the model. We'll use an 'l1' penalty to regularize the regression for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitReg = LogisticRegression(penalty='l1', \n",
    "                              solver='liblinear', \n",
    "                              C=1, \n",
    "                              max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Train the model (for now we'll use a 1-fold split... aka what we've done in the past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Get predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category predictions using 0.5 threshold\n",
    "yhat = logitReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0,1) predictive probabilities\n",
    "phat01 = logitReg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6932936 , 0.3067064 ],\n",
       "       [0.97686061, 0.02313939],\n",
       "       [0.98620941, 0.01379059],\n",
       "       [0.00512146, 0.99487854],\n",
       "       [0.90071749, 0.09928251]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat01[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.06706403e-01, 2.31393948e-02, 1.37905907e-02, 9.94878540e-01,\n",
       "       9.92825058e-02, 1.90376145e-02, 6.57872625e-03, 2.23362678e-03,\n",
       "       3.80080428e-01, 1.41567279e-01, 6.79882444e-01, 1.48639985e-02,\n",
       "       3.65025946e-02, 9.92545221e-01, 9.44923312e-01, 4.64036069e-03,\n",
       "       2.43577570e-01, 6.92031058e-01, 2.82355052e-01, 1.35650095e-02,\n",
       "       3.97975802e-04, 6.97796832e-04, 2.53443624e-01, 9.99058499e-01,\n",
       "       8.17926320e-01, 4.59442716e-04, 6.46822475e-01, 8.87206409e-01,\n",
       "       2.39646059e-01, 4.00899276e-02, 2.31581710e-01, 9.61382651e-02,\n",
       "       7.82486981e-01, 7.57412455e-01, 4.87865283e-01, 8.57162460e-01,\n",
       "       3.27152350e-03, 2.50055945e-01, 1.08285135e-01, 3.59258526e-01])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat1 = phat01[:,1]\n",
    "phat1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy:\n",
    "score = logitReg.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  3],\n",
       "       [ 4,  9]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows are actual labels (0, 1), columns are predicted label (0,1)\n",
    "cm = metrics.confusion_matrix(y_test, yhat)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix visualization using heatmap**\n",
    "\n",
    "Code adapted from: ([Galarnyk, 2017](https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "fig = sns.heatmap(cm, annot=True, annot_kws={\"size\": 16},\n",
    "                 square=True, \n",
    "                 linewidths=0.5, \n",
    "                 cmap = 'Blues_r')\n",
    "fig.set_ylim([0,2])\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 12)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the cells are arranged so the lower left (0,0) and upper right (1,1) are the correct classfication counts for true negatives and true positives, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensitivity and specificity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senspec(y, score, thresh, index=0):\n",
    "    yhat = 1*(score >= thresh)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_true=y, \n",
    "                                              y_pred=yhat).ravel()\n",
    "    sens = tp / (fn + tp)\n",
    "    spec = tn / (fp + tn)\n",
    "    accuracy = (tn+tp)/(tn+fp+fn+tp)\n",
    "    return pd.DataFrame({'tn':[tn], \n",
    "                         'fp':[fp], \n",
    "                         'fn':[fn], \n",
    "                         'tp':[tp], \n",
    "                         'sens':[sens], \n",
    "                         'spec':[spec],\n",
    "                         'accuracy':[accuracy]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tn  fp  fn  tp      sens      spec  accuracy\n",
       "0  24   3   4   9  0.692308  0.888889     0.825"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senspec(y_test, phat1, 0.5)  # 0.5 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tn  fp  fn  tp      sens      spec  accuracy\n",
       "0  23   4   2  11  0.846154  0.851852      0.85"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senspec(y_test, phat1, 0.33)  # 0.33 threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, score = metrics.roc_curve(y_true=y_test, y_score=phat1)\n",
    "auc = metrics.roc_auc_score(y_true=y_test, y_score=phat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, auc, lw=2):\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw,\n",
    "             label='ROC curve (area = '+str(round(auc,3))+')')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(fpr, tpr, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next let's train each of the four regularization types (ie. none, L1, L2, and elastic net) Using Cross Validation Scoring.\n",
    "\n",
    "In cross validation, we cycle through all the k-fold train/test splits of the data using each 1/k subset as the test set with the other 1 - 1/k as the training set. In this way we obtain k different splits of the data. We average over the k splits. The variation in performance scores can also gives us a standard error on the performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.825, 0.675, 0.8  , 0.85 , 0.9  ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modclass0 = LogisticRegression(penalty='none', solver='newton-cg')\n",
    "scores0 = cross_val_score(modclass0, X, y, cv=5)\n",
    "scores0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores0.mean(), 2*scores0.std()/np.sqrt(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.825, 0.75 , 0.8  , 0.8  , 0.85 ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modclass1 = LogisticRegression(penalty='l1', \n",
    "                               solver='saga', \n",
    "                               C=0.3, \n",
    "                               max_iter=1000)\n",
    "scores1 = cross_val_score(modclass1, X, y, cv=5)\n",
    "scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % \\\n",
    "      (scores1.mean(), 2*scores1.std()/np.sqrt(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.825, 0.75 , 0.8  , 0.85 , 0.9  ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modclass2 = LogisticRegression(penalty='l2', \n",
    "                               solver='saga', \n",
    "                               C=0.3, \n",
    "                               max_iter=1000)\n",
    "scores2 = cross_val_score(modclass2, X, y, cv=5)\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % \\\n",
    "      (scores2.mean(), 2*scores2.std()/np.sqrt(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Elastic Net regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.825, 0.75 , 0.825, 0.85 , 0.85 ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modclass3 = LogisticRegression(penalty='elasticnet', \n",
    "                               solver='saga', \n",
    "                               l1_ratio=0.75, \n",
    "                               C=0.3, \n",
    "                               max_iter=1000)\n",
    "scores3 = cross_val_score(modclass3, X, y, cv=5)\n",
    "scores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % \\\n",
    "      (scores3.mean(), 2*scores3.std()/np.sqrt(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "STAT 207, Victoria Ellison and Douglas Simpson, University of Illinois at Urbana-Champaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
